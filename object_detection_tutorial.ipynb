{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V8-yl-s-WKMG"
   },
   "source": [
    "# Object Detection Demo\n",
    "Welcome to the object detection inference walkthrough!  This notebook will walk you step by step through the process of using a pre-trained model to detect objects in an image. Make sure to follow the [installation instructions](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/installation.md) before you start."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kFSqkTCdWKMI"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "hV4P5gyTWKMI"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import six.moves.urllib as urllib\n",
    "import sys\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "import time\n",
    "\n",
    "from distutils.version import StrictVersion\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# This is needed since the notebook is stored in the object_detection folder.\n",
    "sys.path.append(\".\")\n",
    "#from object_detection.utils import ops as utils_ops\n",
    "\n",
    "#if StrictVersion(tf.__version__) < StrictVersion('1.12.0'):\n",
    "#    raise ImportError('Please upgrade your TensorFlow installation to v1.12.*.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cfn_tRFOWKMO"
   },
   "source": [
    "# Model preparation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X_sEBLpVWKMQ"
   },
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inference configs\n",
    "IMAGE_PATH = '/home/johann/Pictures'\n",
    "DESTINATION_PATH = '/home/johann/Pictures/done'\n",
    "IMAGE_DIMS = [300, 300]\n",
    "FIGURE_DIMS = tuple(IMAGE_DIMS.copy())\n",
    "BATCH_NUM = 1\n",
    "THRESHOLD = 1\n",
    "\n",
    "# What model to download.\n",
    "MODEL_NAME = 'ssd_mobilenet_v1_0.75_depth_300x300_coco14_sync_2018_07_03'\n",
    "MODEL_FILE = MODEL_NAME + '.tar.gz'\n",
    "INFERENCE_GRAPH_PATH = MODEL_NAME + '/frozen_inference_graph.pb'\n",
    "\n",
    "#Download url\n",
    "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
    "\n",
    "VISUALIZE = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "KILYnwR5WKMS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model file already exists\n",
      "Model file already extracted\n"
     ]
    }
   ],
   "source": [
    "if not os.path.isfile(MODEL_FILE):\n",
    "    print(\"Downloading model file\")\n",
    "    opener = urllib.request.URLopener()\n",
    "    opener.retrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
    "else:\n",
    "    print(\"Model file already exists\")\n",
    "    \n",
    "if not os.path.isfile(INFERENCE_GRAPH_PATH):\n",
    "    tar_file = tarfile.open(MODEL_FILE)\n",
    "    for file in tar_file.getmembers():\n",
    "        file_name = os.path.basename(file.name)\n",
    "        if 'frozen_inference_graph.pb' in file_name:\n",
    "            tar_file.extract(file, os.getcwd())\n",
    "else:\n",
    "    print('Model file already extracted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_1MVVTcLWKMW"
   },
   "source": [
    "## Loading label map\n",
    "Label maps map indices to category names, so that when our convolution network predicts `5`, we know that this corresponds to `airplane`.  Here we use internal utility functions, but anything that returns a dictionary mapping integers to appropriate string labels would be fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORY_INDEX = {}\n",
    "f = open(\"object_detection/mscoco_label_map.pbtxt\", \"r\")\n",
    "for line in f:\n",
    "    if 'item' in line:\n",
    "        name = f.readline().split()[1]\n",
    "        real_id = int(f.readline().split()[1])\n",
    "        real_name = f.readline().split()[1]\n",
    "        CATEGORY_INDEX[real_id] =  {'id': real_id, 'name': real_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: {'id': 1, 'name': 'person'}, 2: {'id': 2, 'name': 'bicycle'}, 3: {'id': 3, 'name': 'car'}, 4: {'id': 4, 'name': 'motorcycle'}, 5: {'id': 5, 'name': 'airplane'}, 6: {'id': 6, 'name': 'bus'}, 7: {'id': 7, 'name': 'train'}, 8: {'id': 8, 'name': 'truck'}, 9: {'id': 9, 'name': 'boat'}, 10: {'id': 10, 'name': 'traffic'}, 11: {'id': 11, 'name': 'fire'}, 13: {'id': 13, 'name': 'stop'}, 14: {'id': 14, 'name': 'parking'}, 15: {'id': 15, 'name': 'bench'}, 16: {'id': 16, 'name': 'bird'}, 17: {'id': 17, 'name': 'cat'}, 18: {'id': 18, 'name': 'dog'}, 19: {'id': 19, 'name': 'horse'}, 20: {'id': 20, 'name': 'sheep'}, 21: {'id': 21, 'name': 'cow'}, 22: {'id': 22, 'name': 'elephant'}, 23: {'id': 23, 'name': 'bear'}, 24: {'id': 24, 'name': 'zebra'}, 25: {'id': 25, 'name': 'giraffe'}, 27: {'id': 27, 'name': 'backpack'}, 28: {'id': 28, 'name': 'umbrella'}, 31: {'id': 31, 'name': 'handbag'}, 32: {'id': 32, 'name': 'tie'}, 33: {'id': 33, 'name': 'suitcase'}, 34: {'id': 34, 'name': 'frisbee'}, 35: {'id': 35, 'name': 'skis'}, 36: {'id': 36, 'name': 'snowboard'}, 37: {'id': 37, 'name': 'sports'}, 38: {'id': 38, 'name': 'kite'}, 39: {'id': 39, 'name': 'baseball'}, 40: {'id': 40, 'name': 'baseball'}, 41: {'id': 41, 'name': 'skateboard'}, 42: {'id': 42, 'name': 'surfboard'}, 43: {'id': 43, 'name': 'tennis'}, 44: {'id': 44, 'name': 'bottle'}, 46: {'id': 46, 'name': 'wine'}, 47: {'id': 47, 'name': 'cup'}, 48: {'id': 48, 'name': 'fork'}, 49: {'id': 49, 'name': 'knife'}, 50: {'id': 50, 'name': 'spoon'}, 51: {'id': 51, 'name': 'bowl'}, 52: {'id': 52, 'name': 'banana'}, 53: {'id': 53, 'name': 'apple'}, 54: {'id': 54, 'name': 'sandwich'}, 55: {'id': 55, 'name': 'orange'}, 56: {'id': 56, 'name': 'broccoli'}, 57: {'id': 57, 'name': 'carrot'}, 58: {'id': 58, 'name': 'hot'}, 59: {'id': 59, 'name': 'pizza'}, 60: {'id': 60, 'name': 'donut'}, 61: {'id': 61, 'name': 'cake'}, 62: {'id': 62, 'name': 'chair'}, 63: {'id': 63, 'name': 'couch'}, 64: {'id': 64, 'name': 'potted'}, 65: {'id': 65, 'name': 'bed'}, 67: {'id': 67, 'name': 'dining'}, 70: {'id': 70, 'name': 'toilet'}, 72: {'id': 72, 'name': 'tv'}, 73: {'id': 73, 'name': 'laptop'}, 74: {'id': 74, 'name': 'mouse'}, 75: {'id': 75, 'name': 'remote'}, 76: {'id': 76, 'name': 'keyboard'}, 77: {'id': 77, 'name': 'cell'}, 78: {'id': 78, 'name': 'microwave'}, 79: {'id': 79, 'name': 'oven'}, 80: {'id': 80, 'name': 'toaster'}, 81: {'id': 81, 'name': 'sink'}, 82: {'id': 82, 'name': 'refrigerator'}, 84: {'id': 84, 'name': 'book'}, 85: {'id': 85, 'name': 'clock'}, 86: {'id': 86, 'name': 'vase'}, 87: {'id': 87, 'name': 'scissors'}, 88: {'id': 88, 'name': 'teddy'}, 89: {'id': 89, 'name': 'hair'}, 90: {'id': 90, 'name': 'toothbrush'}}\n"
     ]
    }
   ],
   "source": [
    "print(CATEGORY_INDEX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataset as tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(path, image_dims, batch_size = 32):\n",
    "    import pathlib \n",
    "    import random \n",
    "    print(image_dims)\n",
    "\n",
    "    \n",
    "    data_root = pathlib.Path(path)\n",
    "    image_uris = list(data_root.glob('**/*.jpeg'))\n",
    "    print(image_uris)\n",
    "    image_uris = [str(image) for image in image_uris]\n",
    "    \n",
    "    def preprocess_image(image):\n",
    "\n",
    "        image = tf.image.decode_jpeg(image, channels=3)\n",
    "        image = tf.image.resize_image_with_pad(image, image_dims[0], image_dims[1])\n",
    "        #image /= 255  # normalize to [0,1] range\n",
    "\n",
    "        return image\n",
    "    \n",
    "    def load_and_preprocess_image(path):\n",
    "        \n",
    "        image = tf.read_file(path)\n",
    "        \n",
    "        return preprocess_image(image)\n",
    "    \n",
    "    path_ds = tf.data.Dataset.from_tensor_slices(image_uris)\n",
    "    #AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "    image_ds = path_ds.map(load_and_preprocess_image)\n",
    "    \n",
    "    return image_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create graph and connect tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_inference_graph(inference_graph_path):\n",
    "    \"\"\"Loads the inference graph and connects it to the input image.\n",
    "    Args:\n",
    "    image_tensor: The input image. uint8 tensor, shape=[1, None, None, 3]\n",
    "    inference_graph_path: Path to the inference graph with embedded weights\n",
    "    Returns:\n",
    "    detected_boxes_tensor: Detected boxes. Float tensor,\n",
    "        shape=[num_detections, 4]\n",
    "    detected_scores_tensor: Detected scores. Float tensor,\n",
    "        shape=[num_detections]\n",
    "    detected_labels_tensor: Detected labels. Int64 tensor,\n",
    "        shape=[num_detections]\n",
    "    \"\"\"\n",
    "    with tf.gfile.Open(inference_graph_path, 'rb') as graph_def_file:\n",
    "        graph_content = graph_def_file.read()\n",
    "    graph_def = tf.GraphDef()\n",
    "    graph_def.MergeFromString(graph_content)\n",
    "\n",
    "    tf.import_graph_def(graph_def, name='')\n",
    "\n",
    "    g = tf.get_default_graph()\n",
    "    \n",
    "    tensor_dict = {}\n",
    "    for key in ['num_detections', 'detection_boxes', 'detection_scores', 'detection_classes']:\n",
    "        tensor_name = key + ':0'\n",
    "        try:\n",
    "            tensor_dict[key] = g.get_tensor_by_name(tensor_name)\n",
    "        except:\n",
    "            print(\"Something went horribly wrong when loading graph tensors\")\n",
    "            pass\n",
    "        \n",
    "    \n",
    "    image_tensor = g.get_tensor_by_name('image_tensor:0')\n",
    "    print(image_tensor)\n",
    "    return tensor_dict, image_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Threaded visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Thread\n",
    "from object_detection.utils import visualization_utils as vis_util\n",
    "\n",
    "def threaded_function(image_np, args_dict, counter, returner=False):\n",
    "    boxes = args_dict['detection_boxes']\n",
    "    scores = args_dict['detection_scores']\n",
    "    classes = np.array(output_dict['detection_classes'], np.int16)\n",
    "    \n",
    "    for i in range(len(image_np)):\n",
    "        new_img = np.array(image_np[i], np.uint8)\n",
    "        vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "          new_img,\n",
    "          boxes[i],\n",
    "          classes[i],\n",
    "          scores[i],\n",
    "          CATEGORY_INDEX,\n",
    "          use_normalized_coordinates=True,\n",
    "          line_thickness=8)\n",
    "        plt.figure(figsize=FIGURE_DIMS)\n",
    "        plt.imsave(DESTINATION_PATH + '/{}_{}.jpg'.format(str(counter), str(i)), new_img)\n",
    "        plt.close()\n",
    "    if returner:\n",
    "        img = plt.imread(DESTINATION_PATH + '/' + str(counter) + '_0.jpg', format='jpg')\n",
    "        return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actual Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[300, 300]\n",
      "[PosixPath('/home/johann/Pictures/index.jpeg'), PosixPath('/home/johann/Pictures/people.jpeg'), PosixPath('/home/johann/Pictures/images.jpeg')]\n",
      "WARNING:tensorflow:From /home/johann/.local/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "INFO:tensorflow:Reading input from files and connecting to graph\n",
      "INFO:tensorflow:Reading graph and building model\n"
     ]
    }
   ],
   "source": [
    "ds = create_dataset(IMAGE_PATH, IMAGE_DIMS)\n",
    "ds = ds.prefetch(BATCH_NUM*2).batch(BATCH_NUM)\n",
    "it = ds.make_one_shot_iterator()\n",
    "\n",
    "# This is needed to display the images.\n",
    "%matplotlib inline\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.logging.info('Reading input from files and connecting to graph')\n",
    "    #image_tensor = build_input(image_path)\n",
    "    \n",
    "    tf.logging.info('Reading graph and building model')\n",
    "    tensor_dict, image_tensor = build_inference_graph(INFERENCE_GRAPH_PATH)\n",
    "    \n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    image_it = it.get_next()\n",
    "    \n",
    "    threads = []\n",
    "    i = 1\n",
    "    j = 1\n",
    "    try:\n",
    "        while True:\n",
    "            print('Step: ' + str(i))\n",
    "            start = time.time()\n",
    "            with tf.device('/gpu:0'):\n",
    "                \n",
    "                image = sess.run(image_it)\n",
    "                print('Time required for reading: ' + str(time.time() - start))\n",
    "\n",
    "                start = time.time()\n",
    "                output_dict = sess.run(tensor_dict, feed_dict = {image_tensor: image})\n",
    "                print('Time required for computation: ' + str(time.time() - start))\n",
    "            \n",
    "                        \n",
    "            if (i % THRESHOLD == 0):\n",
    "                img = threaded_function(image, output_dict, i, True)\n",
    "                plt.imshow(img)\n",
    "                plt.show()\n",
    "                plt.close()\n",
    "            else: \n",
    "                if VISUALIZE:\n",
    "                    thread = Thread(target = threaded_function, args = (image, output_dict, i))\n",
    "                    thread.start()\n",
    "                    threads.append(thread)\n",
    "                \n",
    "            i += 1\n",
    "            \n",
    "                \n",
    "    \n",
    "    except tf.errors.OutOfRangeError:\n",
    "        tf.logging.info('Finished processing records')\n",
    "        for t in threads:\n",
    "            t.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "object_detection_tutorial.ipynb?workspaceId=ronnyvotel:python_inference::citc",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
