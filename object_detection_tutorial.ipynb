{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V8-yl-s-WKMG"
   },
   "source": [
    "# Object Detection Demo\n",
    "Welcome to the object detection inference walkthrough!  This notebook will walk you step by step through the process of using a pre-trained model to detect objects in an image. Make sure to follow the [installation instructions](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/installation.md) before you start."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kFSqkTCdWKMI"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "hV4P5gyTWKMI"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import six.moves.urllib as urllib\n",
    "import sys\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "import time\n",
    "\n",
    "import pprint\n",
    "\n",
    "from distutils.version import StrictVersion\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# This is needed since the notebook is stored in the object_detection folder.\n",
    "sys.path.append(\".\")\n",
    "#from object_detection.utils import ops as utils_ops\n",
    "\n",
    "#if StrictVersion(tf.__version__) < StrictVersion('1.12.0'):\n",
    "#    raise ImportError('Please upgrade your TensorFlow installation to v1.12.*.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cfn_tRFOWKMO"
   },
   "source": [
    "# Model preparation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X_sEBLpVWKMQ"
   },
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inference configs\n",
    "IMAGE_PATH = '/home/jovyan/aidata-volume/AI_Datasets/val2017'\n",
    "DESTINATION_PATH = '/home/jovyan/'\n",
    "IMAGE_DIMS = [300, 300]\n",
    "FIGURE_DIMS = tuple(IMAGE_DIMS.copy())\n",
    "BATCH_NUM = 200\n",
    "THRESHOLD = 20\n",
    "\n",
    "# What model to download.\n",
    "MODEL_NAME = 'ssd_mobilenet_v1_0.75_depth_300x300_coco14_sync_2018_07_03'\n",
    "MODEL_FILE = MODEL_NAME + '.tar.gz'\n",
    "INFERENCE_GRAPH_PATH = MODEL_NAME + '/frozen_inference_graph.pb'\n",
    "\n",
    "#Download url\n",
    "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
    "\n",
    "VISUALIZE = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "KILYnwR5WKMS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model file already exists\n",
      "Model file already extracted\n"
     ]
    }
   ],
   "source": [
    "if not os.path.isfile(MODEL_FILE):\n",
    "    print(\"Downloading model file\")\n",
    "    opener = urllib.request.URLopener()\n",
    "    opener.retrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
    "else:\n",
    "    print(\"Model file already exists\")\n",
    "    \n",
    "if not os.path.isfile(INFERENCE_GRAPH_PATH):\n",
    "    tar_file = tarfile.open(MODEL_FILE)\n",
    "    for file in tar_file.getmembers():\n",
    "        file_name = os.path.basename(file.name)\n",
    "        if 'frozen_inference_graph.pb' in file_name:\n",
    "            tar_file.extract(file, os.getcwd())\n",
    "else:\n",
    "    print('Model file already extracted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_1MVVTcLWKMW"
   },
   "source": [
    "## Loading label map\n",
    "Label maps map indices to category names, so that when our convolution network predicts `5`, we know that this corresponds to `airplane`.  Here we use internal utility functions, but anything that returns a dictionary mapping integers to appropriate string labels would be fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORY_INDEX = {}\n",
    "f = open(\"object_detection/mscoco_label_map.pbtxt\", \"r\")\n",
    "for line in f:\n",
    "    if 'item' in line:\n",
    "        name = f.readline().split()[1]\n",
    "        real_id = int(f.readline().split()[1])\n",
    "        real_name = f.readline().split()[1]\n",
    "        CATEGORY_INDEX[real_id] =  {'id': real_id, 'name': real_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: {'id': 1, 'name': 'person'}, 2: {'id': 2, 'name': 'bicycle'}, 3: {'id': 3, 'name': 'car'}, 4: {'id': 4, 'name': 'motorcycle'}, 5: {'id': 5, 'name': 'airplane'}, 6: {'id': 6, 'name': 'bus'}, 7: {'id': 7, 'name': 'train'}, 8: {'id': 8, 'name': 'truck'}, 9: {'id': 9, 'name': 'boat'}, 10: {'id': 10, 'name': 'traffic'}, 11: {'id': 11, 'name': 'fire'}, 13: {'id': 13, 'name': 'stop'}, 14: {'id': 14, 'name': 'parking'}, 15: {'id': 15, 'name': 'bench'}, 16: {'id': 16, 'name': 'bird'}, 17: {'id': 17, 'name': 'cat'}, 18: {'id': 18, 'name': 'dog'}, 19: {'id': 19, 'name': 'horse'}, 20: {'id': 20, 'name': 'sheep'}, 21: {'id': 21, 'name': 'cow'}, 22: {'id': 22, 'name': 'elephant'}, 23: {'id': 23, 'name': 'bear'}, 24: {'id': 24, 'name': 'zebra'}, 25: {'id': 25, 'name': 'giraffe'}, 27: {'id': 27, 'name': 'backpack'}, 28: {'id': 28, 'name': 'umbrella'}, 31: {'id': 31, 'name': 'handbag'}, 32: {'id': 32, 'name': 'tie'}, 33: {'id': 33, 'name': 'suitcase'}, 34: {'id': 34, 'name': 'frisbee'}, 35: {'id': 35, 'name': 'skis'}, 36: {'id': 36, 'name': 'snowboard'}, 37: {'id': 37, 'name': 'sports'}, 38: {'id': 38, 'name': 'kite'}, 39: {'id': 39, 'name': 'baseball'}, 40: {'id': 40, 'name': 'baseball'}, 41: {'id': 41, 'name': 'skateboard'}, 42: {'id': 42, 'name': 'surfboard'}, 43: {'id': 43, 'name': 'tennis'}, 44: {'id': 44, 'name': 'bottle'}, 46: {'id': 46, 'name': 'wine'}, 47: {'id': 47, 'name': 'cup'}, 48: {'id': 48, 'name': 'fork'}, 49: {'id': 49, 'name': 'knife'}, 50: {'id': 50, 'name': 'spoon'}, 51: {'id': 51, 'name': 'bowl'}, 52: {'id': 52, 'name': 'banana'}, 53: {'id': 53, 'name': 'apple'}, 54: {'id': 54, 'name': 'sandwich'}, 55: {'id': 55, 'name': 'orange'}, 56: {'id': 56, 'name': 'broccoli'}, 57: {'id': 57, 'name': 'carrot'}, 58: {'id': 58, 'name': 'hot'}, 59: {'id': 59, 'name': 'pizza'}, 60: {'id': 60, 'name': 'donut'}, 61: {'id': 61, 'name': 'cake'}, 62: {'id': 62, 'name': 'chair'}, 63: {'id': 63, 'name': 'couch'}, 64: {'id': 64, 'name': 'potted'}, 65: {'id': 65, 'name': 'bed'}, 67: {'id': 67, 'name': 'dining'}, 70: {'id': 70, 'name': 'toilet'}, 72: {'id': 72, 'name': 'tv'}, 73: {'id': 73, 'name': 'laptop'}, 74: {'id': 74, 'name': 'mouse'}, 75: {'id': 75, 'name': 'remote'}, 76: {'id': 76, 'name': 'keyboard'}, 77: {'id': 77, 'name': 'cell'}, 78: {'id': 78, 'name': 'microwave'}, 79: {'id': 79, 'name': 'oven'}, 80: {'id': 80, 'name': 'toaster'}, 81: {'id': 81, 'name': 'sink'}, 82: {'id': 82, 'name': 'refrigerator'}, 84: {'id': 84, 'name': 'book'}, 85: {'id': 85, 'name': 'clock'}, 86: {'id': 86, 'name': 'vase'}, 87: {'id': 87, 'name': 'scissors'}, 88: {'id': 88, 'name': 'teddy'}, 89: {'id': 89, 'name': 'hair'}, 90: {'id': 90, 'name': 'toothbrush'}}\n"
     ]
    }
   ],
   "source": [
    "print(CATEGORY_INDEX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataset as tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(path, image_dims, batch_size = 32):\n",
    "    import pathlib \n",
    "    import random \n",
    "    print(image_dims)\n",
    "\n",
    "    \n",
    "    data_root = pathlib.Path(path)\n",
    "    image_uris = list(data_root.glob('**/*.jpg'))\n",
    "    image_uris = [str(image) for image in image_uris]\n",
    "    \n",
    "    def preprocess_image(image):\n",
    "\n",
    "        image = tf.image.decode_jpeg(image, channels=3)\n",
    "        image = tf.image.resize_image_with_pad(image, image_dims[0], image_dims[1])\n",
    "        #image /= 255  # normalize to [0,1] range\n",
    "\n",
    "        return image\n",
    "    \n",
    "    def load_and_preprocess_image(path):\n",
    "        \n",
    "        image = tf.read_file(path)\n",
    "        \n",
    "        return preprocess_image(image)\n",
    "    \n",
    "    path_ds = tf.data.Dataset.from_tensor_slices(image_uris)\n",
    "    #AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "    image_ds = path_ds.map(load_and_preprocess_image)\n",
    "    \n",
    "    return image_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create graph and connect tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_inference_graph(inference_graph_path, d):\n",
    "    \"\"\"Loads the inference graph and connects it to the input image.\n",
    "    Args:\n",
    "    image_tensor: The input image. uint8 tensor, shape=[1, None, None, 3]\n",
    "    inference_graph_path: Path to the inference graph with embedded weights\n",
    "    Returns:\n",
    "    detected_boxes_tensor: Detected boxes. Float tensor,\n",
    "        shape=[num_detections, 4]\n",
    "    detected_scores_tensor: Detected scores. Float tensor,\n",
    "        shape=[num_detections]\n",
    "    detected_labels_tensor: Detected labels. Int64 tensor,\n",
    "        shape=[num_detections]\n",
    "    \"\"\"\n",
    "    #tf.reset_default_graph()\n",
    "    with tf.gfile.Open(inference_graph_path, 'rb') as graph_def_file:\n",
    "        graph_content = graph_def_file.read()\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.MergeFromString(graph_content)\n",
    "\n",
    "\n",
    "    # Then, we can use again a convenient built-in function to import a graph_def into the \n",
    "    # current default Graph\n",
    "    with tf.Graph().as_default() as graph:\n",
    "        with tf.device(d):\n",
    "            tf.import_graph_def(\n",
    "                graph_def,\n",
    "                name = ''\n",
    "            )\n",
    "\n",
    "    #graph = tf.get_default_graph()\n",
    "    tensor_dict = {}\n",
    "    #image_tensor = None\n",
    "    for key in ['num_detections', 'detection_boxes', 'detection_scores', 'detection_classes']:\n",
    "        tensor_name = key + ':0'\n",
    "        try:\n",
    "            tensor_dict[key] = graph.get_tensor_by_name(tensor_name)\n",
    "        except:\n",
    "            print(\"Something went horribly wrong when loading graph tensors\")\n",
    "            pass\n",
    "\n",
    "\n",
    "    image_tensor = graph.get_tensor_by_name('image_tensor:0')\n",
    "    tf.reset_default_graph()\n",
    "    return {'out': tensor_dict, 'in': image_tensor}, graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Threaded visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Thread\n",
    "from object_detection.utils import visualization_utils as vis_util\n",
    "\n",
    "vis_threads = []\n",
    "\n",
    "def threaded_function(image_np, args_dict, counter):\n",
    "    boxes = args_dict['detection_boxes']\n",
    "    scores = args_dict['detection_scores']\n",
    "    classes = np.array(args_dict['detection_classes'], np.int16)\n",
    "    \n",
    "    for i in range(len(image_np)):\n",
    "        new_img = np.array(image_np[i], np.uint8)\n",
    "        vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "          new_img,\n",
    "          boxes[i],\n",
    "          classes[i],\n",
    "          scores[i],\n",
    "          CATEGORY_INDEX,\n",
    "          use_normalized_coordinates=True,\n",
    "          line_thickness=8)\n",
    "        plt.figure(figsize=FIGURE_DIMS)\n",
    "        #plt.imsave(DESTINATION_PATH + '/{}_{}.jpg'.format(str(counter), str(i)), new_img)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threaded_inference(device, tensor_dict, image_tensor, graph, image, counter):\n",
    "    print(image_tensor)  <y\n",
    "    with tf.Session(graph = graph) as sess:\n",
    "        output_dict = sess.run(tensor_dict, feed_dict = {image_tensor: image})\n",
    "\n",
    "        if VISUALIZE:\n",
    "                thread = Thread(target = threaded_function, args = (image, output_dict, counter))\n",
    "                thread.start()\n",
    "                vis_threads.append(thread)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actual Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    #return [x.name for x in local_device_protos if (x.device_type == 'GPU' or x.device_type == 'CPU')]\n",
    "    return [x.name for x in local_device_protos if (x.device_type == 'GPU')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/device:GPU:0', '/device:GPU:1', '/device:GPU:2', '/device:GPU:3', '/device:GPU:4', '/device:GPU:5', '/device:GPU:6', '/device:GPU:7']\n"
     ]
    }
   ],
   "source": [
    "print(get_available_gpus())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[300, 300]\n",
      "INFO:tensorflow:Reading graph and building model specified for the different cluster devices\n",
      "/device:GPU:0 loading graph done!\n",
      "/device:GPU:1 loading graph done!\n",
      "/device:GPU:2 loading graph done!\n",
      "/device:GPU:3 loading graph done!\n",
      "/device:GPU:4 loading graph done!\n",
      "/device:GPU:5 loading graph done!\n",
      "/device:GPU:6 loading graph done!\n",
      "/device:GPU:7 loading graph done!\n",
      "Step: 1\n",
      "Tensor(\"image_tensor:0\", shape=(?, ?, ?, 3), dtype=uint8, device=/device:GPU:0)\n",
      "['/device:GPU:0', '/device:GPU:1', '/device:GPU:2', '/device:GPU:3', '/device:GPU:4', '/device:GPU:5', '/device:GPU:6', '/device:GPU:7']\n",
      "Tensor(\"image_tensor:0\", shape=(?, ?, ?, 3), dtype=uint8, device=/device:GPU:1)\n",
      "['/device:GPU:0', '/device:GPU:1', '/device:GPU:2', '/device:GPU:3', '/device:GPU:4', '/device:GPU:5', '/device:GPU:6', '/device:GPU:7']\n",
      "Tensor(\"image_tensor:0\", shape=(?, ?, ?, 3), dtype=uint8, device=/device:GPU:2)\n",
      "['/device:GPU:0', '/device:GPU:1', '/device:GPU:2', '/device:GPU:3', '/device:GPU:4', '/device:GPU:5', '/device:GPU:6', '/device:GPU:7']\n",
      "Tensor(\"image_tensor:0\", shape=(?, ?, ?, 3), dtype=uint8, device=/device:GPU:3)\n",
      "['/device:GPU:0', '/device:GPU:1', '/device:GPU:2', '/device:GPU:3', '/device:GPU:4', '/device:GPU:5', '/device:GPU:6', '/device:GPU:7']\n",
      "Tensor(\"image_tensor:0\", shape=(?, ?, ?, 3), dtype=uint8, device=/device:GPU:4)\n",
      "['/device:GPU:0', '/device:GPU:1', '/device:GPU:2', '/device:GPU:3', '/device:GPU:4', '/device:GPU:5', '/device:GPU:6', '/device:GPU:7']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-4:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1334, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1317, in _run_fn\n",
      "    self._extend_graph()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1352, in _extend_graph\n",
      "    tf_session.ExtendSession(self._session)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:0\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:0\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:0\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:0\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:0\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[{{node Preprocessor/map/TensorArray_2}} = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:0\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-9-04675268f0aa>\", line 5, in threaded_inference\n",
      "    output_dict = sess.run(tensor_dict, feed_dict = {image_tensor: image})\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 929, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1152, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1328, in _do_run\n",
      "    run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1348, in _do_call\n",
      "    raise type(e)(node_def, op, message)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:0\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:0\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:0\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:0\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:0\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:0\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "Caused by op 'Preprocessor/map/TensorArray_2', defined at:\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 1431, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 346, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1080, in __init__\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-1d8adc307096>\", line 18, in <module>\n",
      "    tensors, graph = build_inference_graph(INFERENCE_GRAPH_PATH, d)\n",
      "  File \"<ipython-input-7-a0e1e0e6caa2>\", line 27, in build_inference_graph\n",
      "    name = ''\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 442, in import_graph_def\n",
      "    _ProcessNewOps(graph)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 234, in _ProcessNewOps\n",
      "    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in _add_new_tf_operations\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in <listcomp>\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3299, in _create_op_from_tf_operation\n",
      "    ret = Operation(c_op, self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n",
      "InvalidArgumentError (see above for traceback): Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:0\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:0\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:0\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:0\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:0\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:0\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-5:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1334, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1317, in _run_fn\n",
      "    self._extend_graph()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1352, in _extend_graph\n",
      "    tf_session.ExtendSession(self._session)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:1' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:1\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:1\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:1\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:1\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:1\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[{{node Preprocessor/map/TensorArray_2}} = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:1\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-9-04675268f0aa>\", line 5, in threaded_inference\n",
      "    output_dict = sess.run(tensor_dict, feed_dict = {image_tensor: image})\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 929, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1152, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1328, in _do_run\n",
      "    run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1348, in _do_call\n",
      "    raise type(e)(node_def, op, message)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:1' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:1\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:1\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:1\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:1\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:1\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:1\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "Caused by op 'Preprocessor/map/TensorArray_2', defined at:\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 1431, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 346, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1080, in __init__\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-1d8adc307096>\", line 18, in <module>\n",
      "    tensors, graph = build_inference_graph(INFERENCE_GRAPH_PATH, d)\n",
      "  File \"<ipython-input-7-a0e1e0e6caa2>\", line 27, in build_inference_graph\n",
      "    name = ''\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 442, in import_graph_def\n",
      "    _ProcessNewOps(graph)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 234, in _ProcessNewOps\n",
      "    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in _add_new_tf_operations\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in <listcomp>\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3299, in _create_op_from_tf_operation\n",
      "    ret = Operation(c_op, self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n",
      "InvalidArgumentError (see above for traceback): Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:1' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:1\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:1\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:1\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:1\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:1\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:1\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"image_tensor:0\", shape=(?, ?, ?, 3), dtype=uint8, device=/device:GPU:5)\n",
      "['/device:GPU:0', '/device:GPU:1', '/device:GPU:2', '/device:GPU:3', '/device:GPU:4', '/device:GPU:5', '/device:GPU:6', '/device:GPU:7']\n",
      "Tensor(\"image_tensor:0\", shape=(?, ?, ?, 3), dtype=uint8, device=/device:GPU:6)\n",
      "['/device:GPU:0', '/device:GPU:1', '/device:GPU:2', '/device:GPU:3', '/device:GPU:4', '/device:GPU:5', '/device:GPU:6', '/device:GPU:7']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-6:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1334, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1317, in _run_fn\n",
      "    self._extend_graph()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1352, in _extend_graph\n",
      "    tf_session.ExtendSession(self._session)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:2' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:2\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:2\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:2\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:2\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:2\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[{{node Preprocessor/map/TensorArray_2}} = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:2\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-9-04675268f0aa>\", line 5, in threaded_inference\n",
      "    output_dict = sess.run(tensor_dict, feed_dict = {image_tensor: image})\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 929, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1152, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1328, in _do_run\n",
      "    run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1348, in _do_call\n",
      "    raise type(e)(node_def, op, message)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:2' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:2\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:2\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:2\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:2\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:2\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:2\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "Caused by op 'Preprocessor/map/TensorArray_2', defined at:\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 1431, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 346, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1080, in __init__\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-1d8adc307096>\", line 18, in <module>\n",
      "    tensors, graph = build_inference_graph(INFERENCE_GRAPH_PATH, d)\n",
      "  File \"<ipython-input-7-a0e1e0e6caa2>\", line 27, in build_inference_graph\n",
      "    name = ''\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 442, in import_graph_def\n",
      "    _ProcessNewOps(graph)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 234, in _ProcessNewOps\n",
      "    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in _add_new_tf_operations\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in <listcomp>\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3299, in _create_op_from_tf_operation\n",
      "    ret = Operation(c_op, self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n",
      "InvalidArgumentError (see above for traceback): Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:2' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:2\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:2\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:2\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:2\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:2\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:2\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "\n",
      "Exception in thread Thread-9:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1334, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1317, in _run_fn\n",
      "    self._extend_graph()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1352, in _extend_graph\n",
      "    tf_session.ExtendSession(self._session)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:5' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:5\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:5\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:5\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:5\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:5\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[{{node Preprocessor/map/TensorArray_2}} = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:5\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-9-04675268f0aa>\", line 5, in threaded_inference\n",
      "    output_dict = sess.run(tensor_dict, feed_dict = {image_tensor: image})\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 929, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1152, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1328, in _do_run\n",
      "    run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1348, in _do_call\n",
      "    raise type(e)(node_def, op, message)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:5' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:5\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:5\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:5\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:5\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:5\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:5\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "Caused by op 'Preprocessor/map/TensorArray_2', defined at:\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 1431, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 346, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1080, in __init__\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-1d8adc307096>\", line 18, in <module>\n",
      "    tensors, graph = build_inference_graph(INFERENCE_GRAPH_PATH, d)\n",
      "  File \"<ipython-input-7-a0e1e0e6caa2>\", line 27, in build_inference_graph\n",
      "    name = ''\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 442, in import_graph_def\n",
      "    _ProcessNewOps(graph)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 234, in _ProcessNewOps\n",
      "    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in _add_new_tf_operations\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in <listcomp>\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3299, in _create_op_from_tf_operation\n",
      "    ret = Operation(c_op, self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n",
      "InvalidArgumentError (see above for traceback): Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:5' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:5\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:5\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:5\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:5\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:5\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:5\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "\n",
      "Exception in thread Thread-7:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1334, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1317, in _run_fn\n",
      "    self._extend_graph()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1352, in _extend_graph\n",
      "    tf_session.ExtendSession(self._session)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:3' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:3\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:3\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:3\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:3\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:3\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[{{node Preprocessor/map/TensorArray_2}} = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:3\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-9-04675268f0aa>\", line 5, in threaded_inference\n",
      "    output_dict = sess.run(tensor_dict, feed_dict = {image_tensor: image})\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 929, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1152, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1328, in _do_run\n",
      "    run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1348, in _do_call\n",
      "    raise type(e)(node_def, op, message)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:3' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:3\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:3\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:3\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:3\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:3\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:3\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "Caused by op 'Preprocessor/map/TensorArray_2', defined at:\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 1431, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 346, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1080, in __init__\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-1d8adc307096>\", line 18, in <module>\n",
      "    tensors, graph = build_inference_graph(INFERENCE_GRAPH_PATH, d)\n",
      "  File \"<ipython-input-7-a0e1e0e6caa2>\", line 27, in build_inference_graph\n",
      "    name = ''\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 442, in import_graph_def\n",
      "    _ProcessNewOps(graph)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 234, in _ProcessNewOps\n",
      "    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in _add_new_tf_operations\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in <listcomp>\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3299, in _create_op_from_tf_operation\n",
      "    ret = Operation(c_op, self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n",
      "InvalidArgumentError (see above for traceback): Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:3' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:3\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:3\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:3\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:3\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:3\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:3\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"image_tensor:0\", shape=(?, ?, ?, 3), dtype=uint8, device=/device:GPU:7)\n",
      "['/device:GPU:0', '/device:GPU:1', '/device:GPU:2', '/device:GPU:3', '/device:GPU:4', '/device:GPU:5', '/device:GPU:6', '/device:GPU:7']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-8:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1334, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1317, in _run_fn\n",
      "    self._extend_graph()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1352, in _extend_graph\n",
      "    tf_session.ExtendSession(self._session)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:4' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:4\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:4\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:4\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:4\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:4\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[{{node Preprocessor/map/TensorArray_2}} = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:4\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-9-04675268f0aa>\", line 5, in threaded_inference\n",
      "    output_dict = sess.run(tensor_dict, feed_dict = {image_tensor: image})\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 929, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1152, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1328, in _do_run\n",
      "    run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1348, in _do_call\n",
      "    raise type(e)(node_def, op, message)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:4' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:4\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:4\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:4\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:4\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:4\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:4\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "Caused by op 'Preprocessor/map/TensorArray_2', defined at:\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 1431, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 346, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1080, in __init__\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-1d8adc307096>\", line 18, in <module>\n",
      "    tensors, graph = build_inference_graph(INFERENCE_GRAPH_PATH, d)\n",
      "  File \"<ipython-input-7-a0e1e0e6caa2>\", line 27, in build_inference_graph\n",
      "    name = ''\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 442, in import_graph_def\n",
      "    _ProcessNewOps(graph)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 234, in _ProcessNewOps\n",
      "    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in _add_new_tf_operations\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in <listcomp>\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3299, in _create_op_from_tf_operation\n",
      "    ret = Operation(c_op, self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n",
      "InvalidArgumentError (see above for traceback): Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:4' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:4\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:4\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:4\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:4\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:4\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:4\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "\n",
      "Exception in thread Thread-10:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1334, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1317, in _run_fn\n",
      "    self._extend_graph()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1352, in _extend_graph\n",
      "    tf_session.ExtendSession(self._session)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:6' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:6\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:6\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:6\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:6\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:6\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[{{node Preprocessor/map/TensorArray_2}} = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:6\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-9-04675268f0aa>\", line 5, in threaded_inference\n",
      "    output_dict = sess.run(tensor_dict, feed_dict = {image_tensor: image})\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 929, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1152, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1328, in _do_run\n",
      "    run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1348, in _do_call\n",
      "    raise type(e)(node_def, op, message)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:6' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:6\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:6\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:6\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:6\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:6\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:6\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "Caused by op 'Preprocessor/map/TensorArray_2', defined at:\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 1431, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 346, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1080, in __init__\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-1d8adc307096>\", line 18, in <module>\n",
      "    tensors, graph = build_inference_graph(INFERENCE_GRAPH_PATH, d)\n",
      "  File \"<ipython-input-7-a0e1e0e6caa2>\", line 27, in build_inference_graph\n",
      "    name = ''\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 442, in import_graph_def\n",
      "    _ProcessNewOps(graph)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 234, in _ProcessNewOps\n",
      "    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in _add_new_tf_operations\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in <listcomp>\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3299, in _create_op_from_tf_operation\n",
      "    ret = Operation(c_op, self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n",
      "InvalidArgumentError (see above for traceback): Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:6' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:6\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:6\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:6\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:6\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:6\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:6\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "\n",
      "Exception in thread Thread-11:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1334, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1317, in _run_fn\n",
      "    self._extend_graph()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1352, in _extend_graph\n",
      "    tf_session.ExtendSession(self._session)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:7' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:7\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:7\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:7\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:7\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:7\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[{{node Preprocessor/map/TensorArray_2}} = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:7\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-9-04675268f0aa>\", line 5, in threaded_inference\n",
      "    output_dict = sess.run(tensor_dict, feed_dict = {image_tensor: image})\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 929, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1152, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1328, in _do_run\n",
      "    run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1348, in _do_call\n",
      "    raise type(e)(node_def, op, message)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:7' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:7\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:7\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:7\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:7\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:7\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:7\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "Caused by op 'Preprocessor/map/TensorArray_2', defined at:\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 1431, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 346, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1080, in __init__\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-1d8adc307096>\", line 18, in <module>\n",
      "    tensors, graph = build_inference_graph(INFERENCE_GRAPH_PATH, d)\n",
      "  File \"<ipython-input-7-a0e1e0e6caa2>\", line 27, in build_inference_graph\n",
      "    name = ''\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 442, in import_graph_def\n",
      "    _ProcessNewOps(graph)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 234, in _ProcessNewOps\n",
      "    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in _add_new_tf_operations\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in <listcomp>\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3299, in _create_op_from_tf_operation\n",
      "    ret = Operation(c_op, self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n",
      "InvalidArgumentError (see above for traceback): Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:7' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:7\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:7\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:7\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:7\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:7\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:7\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 9\n",
      "Tensor(\"image_tensor:0\", shape=(?, ?, ?, 3), dtype=uint8, device=/device:GPU:0)\n",
      "['/device:GPU:0', '/device:GPU:1', '/device:GPU:2', '/device:GPU:3', '/device:GPU:4', '/device:GPU:5', '/device:GPU:6', '/device:GPU:7']\n",
      "Tensor(\"image_tensor:0\", shape=(?, ?, ?, 3), dtype=uint8, device=/device:GPU:1)\n",
      "['/device:GPU:0', '/device:GPU:1', '/device:GPU:2', '/device:GPU:3', '/device:GPU:4', '/device:GPU:5', '/device:GPU:6', '/device:GPU:7']\n",
      "Tensor(\"image_tensor:0\", shape=(?, ?, ?, 3), dtype=uint8, device=/device:GPU:2)\n",
      "['/device:GPU:0', '/device:GPU:1', '/device:GPU:2', '/device:GPU:3', '/device:GPU:4', '/device:GPU:5', '/device:GPU:6', '/device:GPU:7']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-12:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1334, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1317, in _run_fn\n",
      "    self._extend_graph()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1352, in _extend_graph\n",
      "    tf_session.ExtendSession(self._session)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:0\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:0\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:0\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:0\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:0\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[{{node Preprocessor/map/TensorArray_2}} = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:0\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-9-04675268f0aa>\", line 5, in threaded_inference\n",
      "    output_dict = sess.run(tensor_dict, feed_dict = {image_tensor: image})\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 929, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1152, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1328, in _do_run\n",
      "    run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1348, in _do_call\n",
      "    raise type(e)(node_def, op, message)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:0\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:0\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:0\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:0\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:0\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:0\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "Caused by op 'Preprocessor/map/TensorArray_2', defined at:\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 1431, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 346, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1080, in __init__\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-1d8adc307096>\", line 18, in <module>\n",
      "    tensors, graph = build_inference_graph(INFERENCE_GRAPH_PATH, d)\n",
      "  File \"<ipython-input-7-a0e1e0e6caa2>\", line 27, in build_inference_graph\n",
      "    name = ''\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 442, in import_graph_def\n",
      "    _ProcessNewOps(graph)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 234, in _ProcessNewOps\n",
      "    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in _add_new_tf_operations\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in <listcomp>\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3299, in _create_op_from_tf_operation\n",
      "    ret = Operation(c_op, self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n",
      "InvalidArgumentError (see above for traceback): Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:0\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:0\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:0\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:0\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:0\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:0\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "\n",
      "Exception in thread Thread-13:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1334, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1317, in _run_fn\n",
      "    self._extend_graph()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1352, in _extend_graph\n",
      "    tf_session.ExtendSession(self._session)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:1' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:1\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:1\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:1\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:1\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:1\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[{{node Preprocessor/map/TensorArray_2}} = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:1\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-9-04675268f0aa>\", line 5, in threaded_inference\n",
      "    output_dict = sess.run(tensor_dict, feed_dict = {image_tensor: image})\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 929, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1152, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1328, in _do_run\n",
      "    run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1348, in _do_call\n",
      "    raise type(e)(node_def, op, message)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:1' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:1\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:1\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:1\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:1\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:1\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:1\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "Caused by op 'Preprocessor/map/TensorArray_2', defined at:\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 1431, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 346, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1080, in __init__\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-1d8adc307096>\", line 18, in <module>\n",
      "    tensors, graph = build_inference_graph(INFERENCE_GRAPH_PATH, d)\n",
      "  File \"<ipython-input-7-a0e1e0e6caa2>\", line 27, in build_inference_graph\n",
      "    name = ''\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 442, in import_graph_def\n",
      "    _ProcessNewOps(graph)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 234, in _ProcessNewOps\n",
      "    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in _add_new_tf_operations\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in <listcomp>\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3299, in _create_op_from_tf_operation\n",
      "    ret = Operation(c_op, self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n",
      "InvalidArgumentError (see above for traceback): Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:1' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:1\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:1\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:1\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:1\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:1\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:1\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"image_tensor:0\", shape=(?, ?, ?, 3), dtype=uint8, device=/device:GPU:3)\n",
      "['/device:GPU:0', '/device:GPU:1', '/device:GPU:2', '/device:GPU:3', '/device:GPU:4', '/device:GPU:5', '/device:GPU:6', '/device:GPU:7']\n",
      "Tensor(\"image_tensor:0\", shape=(?, ?, ?, 3), dtype=uint8, device=/device:GPU:4)\n",
      "['/device:GPU:0', '/device:GPU:1', '/device:GPU:2', '/device:GPU:3', '/device:GPU:4', '/device:GPU:5', '/device:GPU:6', '/device:GPU:7']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-14:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1334, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1317, in _run_fn\n",
      "    self._extend_graph()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1352, in _extend_graph\n",
      "    tf_session.ExtendSession(self._session)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:2' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:2\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:2\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:2\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:2\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:2\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[{{node Preprocessor/map/TensorArray_2}} = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:2\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-9-04675268f0aa>\", line 5, in threaded_inference\n",
      "    output_dict = sess.run(tensor_dict, feed_dict = {image_tensor: image})\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 929, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1152, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1328, in _do_run\n",
      "    run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1348, in _do_call\n",
      "    raise type(e)(node_def, op, message)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:2' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:2\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:2\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:2\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:2\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:2\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:2\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "Caused by op 'Preprocessor/map/TensorArray_2', defined at:\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 1431, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 346, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1080, in __init__\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-1d8adc307096>\", line 18, in <module>\n",
      "    tensors, graph = build_inference_graph(INFERENCE_GRAPH_PATH, d)\n",
      "  File \"<ipython-input-7-a0e1e0e6caa2>\", line 27, in build_inference_graph\n",
      "    name = ''\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 442, in import_graph_def\n",
      "    _ProcessNewOps(graph)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 234, in _ProcessNewOps\n",
      "    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in _add_new_tf_operations\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in <listcomp>\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3299, in _create_op_from_tf_operation\n",
      "    ret = Operation(c_op, self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n",
      "InvalidArgumentError (see above for traceback): Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:2' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:2\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:2\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:2\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:2\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:2\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:2\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "\n",
      "Exception in thread Thread-15:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1334, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1317, in _run_fn\n",
      "    self._extend_graph()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1352, in _extend_graph\n",
      "    tf_session.ExtendSession(self._session)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:3' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:3\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:3\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:3\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:3\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:3\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[{{node Preprocessor/map/TensorArray_2}} = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:3\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-9-04675268f0aa>\", line 5, in threaded_inference\n",
      "    output_dict = sess.run(tensor_dict, feed_dict = {image_tensor: image})\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 929, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1152, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1328, in _do_run\n",
      "    run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1348, in _do_call\n",
      "    raise type(e)(node_def, op, message)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:3' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:3\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:3\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:3\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:3\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:3\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:3\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "Caused by op 'Preprocessor/map/TensorArray_2', defined at:\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 1431, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 346, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1080, in __init__\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-1d8adc307096>\", line 18, in <module>\n",
      "    tensors, graph = build_inference_graph(INFERENCE_GRAPH_PATH, d)\n",
      "  File \"<ipython-input-7-a0e1e0e6caa2>\", line 27, in build_inference_graph\n",
      "    name = ''\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 442, in import_graph_def\n",
      "    _ProcessNewOps(graph)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 234, in _ProcessNewOps\n",
      "    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in _add_new_tf_operations\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in <listcomp>\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3299, in _create_op_from_tf_operation\n",
      "    ret = Operation(c_op, self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n",
      "InvalidArgumentError (see above for traceback): Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:3' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:3\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:3\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:3\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:3\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:3\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:3\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"image_tensor:0\", shape=(?, ?, ?, 3), dtype=uint8, device=/device:GPU:5)\n",
      "['/device:GPU:0', '/device:GPU:1', '/device:GPU:2', '/device:GPU:3', '/device:GPU:4', '/device:GPU:5', '/device:GPU:6', '/device:GPU:7']\n",
      "Tensor(\"image_tensor:0\", shape=(?, ?, ?, 3), dtype=uint8, device=/device:GPU:6)\n",
      "['/device:GPU:0', '/device:GPU:1', '/device:GPU:2', '/device:GPU:3', '/device:GPU:4', '/device:GPU:5', '/device:GPU:6', '/device:GPU:7']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-16:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1334, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1317, in _run_fn\n",
      "    self._extend_graph()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1352, in _extend_graph\n",
      "    tf_session.ExtendSession(self._session)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:4' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:4\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:4\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:4\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:4\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:4\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[{{node Preprocessor/map/TensorArray_2}} = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:4\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-9-04675268f0aa>\", line 5, in threaded_inference\n",
      "    output_dict = sess.run(tensor_dict, feed_dict = {image_tensor: image})\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 929, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1152, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1328, in _do_run\n",
      "    run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1348, in _do_call\n",
      "    raise type(e)(node_def, op, message)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:4' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:4\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:4\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:4\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:4\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:4\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:4\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "Caused by op 'Preprocessor/map/TensorArray_2', defined at:\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 1431, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 346, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1080, in __init__\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-1d8adc307096>\", line 18, in <module>\n",
      "    tensors, graph = build_inference_graph(INFERENCE_GRAPH_PATH, d)\n",
      "  File \"<ipython-input-7-a0e1e0e6caa2>\", line 27, in build_inference_graph\n",
      "    name = ''\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 442, in import_graph_def\n",
      "    _ProcessNewOps(graph)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 234, in _ProcessNewOps\n",
      "    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in _add_new_tf_operations\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in <listcomp>\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3299, in _create_op_from_tf_operation\n",
      "    ret = Operation(c_op, self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n",
      "InvalidArgumentError (see above for traceback): Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:4' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:4\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:4\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:4\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:4\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:4\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:4\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"image_tensor:0\", shape=(?, ?, ?, 3), dtype=uint8, device=/device:GPU:7)\n",
      "['/device:GPU:0', '/device:GPU:1', '/device:GPU:2', '/device:GPU:3', '/device:GPU:4', '/device:GPU:5', '/device:GPU:6', '/device:GPU:7']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-18:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1334, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1317, in _run_fn\n",
      "    self._extend_graph()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1352, in _extend_graph\n",
      "    tf_session.ExtendSession(self._session)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:6' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:6\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:6\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:6\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:6\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:6\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[{{node Preprocessor/map/TensorArray_2}} = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:6\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-9-04675268f0aa>\", line 5, in threaded_inference\n",
      "    output_dict = sess.run(tensor_dict, feed_dict = {image_tensor: image})\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 929, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1152, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1328, in _do_run\n",
      "    run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1348, in _do_call\n",
      "    raise type(e)(node_def, op, message)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:6' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:6\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:6\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:6\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:6\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:6\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:6\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "Caused by op 'Preprocessor/map/TensorArray_2', defined at:\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 1431, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 346, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1080, in __init__\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-1d8adc307096>\", line 18, in <module>\n",
      "    tensors, graph = build_inference_graph(INFERENCE_GRAPH_PATH, d)\n",
      "  File \"<ipython-input-7-a0e1e0e6caa2>\", line 27, in build_inference_graph\n",
      "    name = ''\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 442, in import_graph_def\n",
      "    _ProcessNewOps(graph)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 234, in _ProcessNewOps\n",
      "    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in _add_new_tf_operations\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in <listcomp>\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3299, in _create_op_from_tf_operation\n",
      "    ret = Operation(c_op, self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n",
      "InvalidArgumentError (see above for traceback): Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:6' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:6\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:6\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:6\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:6\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:6\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:6\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "\n",
      "Exception in thread Thread-17:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1334, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1317, in _run_fn\n",
      "    self._extend_graph()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1352, in _extend_graph\n",
      "    tf_session.ExtendSession(self._session)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:5' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:5\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:5\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:5\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:5\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:5\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[{{node Preprocessor/map/TensorArray_2}} = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:5\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-9-04675268f0aa>\", line 5, in threaded_inference\n",
      "    output_dict = sess.run(tensor_dict, feed_dict = {image_tensor: image})\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 929, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1152, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1328, in _do_run\n",
      "    run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1348, in _do_call\n",
      "    raise type(e)(node_def, op, message)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:5' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:5\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:5\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:5\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:5\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:5\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:5\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "Caused by op 'Preprocessor/map/TensorArray_2', defined at:\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 1431, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 346, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1080, in __init__\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-1d8adc307096>\", line 18, in <module>\n",
      "    tensors, graph = build_inference_graph(INFERENCE_GRAPH_PATH, d)\n",
      "  File \"<ipython-input-7-a0e1e0e6caa2>\", line 27, in build_inference_graph\n",
      "    name = ''\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 442, in import_graph_def\n",
      "    _ProcessNewOps(graph)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 234, in _ProcessNewOps\n",
      "    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in _add_new_tf_operations\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in <listcomp>\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3299, in _create_op_from_tf_operation\n",
      "    ret = Operation(c_op, self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n",
      "InvalidArgumentError (see above for traceback): Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:5' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:5\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:5\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:5\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:5\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:5\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:5\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "\n",
      "Exception in thread Thread-19:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1334, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1317, in _run_fn\n",
      "    self._extend_graph()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1352, in _extend_graph\n",
      "    tf_session.ExtendSession(self._session)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:7' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:7\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:7\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:7\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:7\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:7\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[{{node Preprocessor/map/TensorArray_2}} = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:7\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-9-04675268f0aa>\", line 5, in threaded_inference\n",
      "    output_dict = sess.run(tensor_dict, feed_dict = {image_tensor: image})\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 929, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1152, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1328, in _do_run\n",
      "    run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1348, in _do_call\n",
      "    raise type(e)(node_def, op, message)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:7' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:7\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:7\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:7\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:7\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:7\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:7\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "Caused by op 'Preprocessor/map/TensorArray_2', defined at:\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 1431, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 346, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1080, in __init__\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-1d8adc307096>\", line 18, in <module>\n",
      "    tensors, graph = build_inference_graph(INFERENCE_GRAPH_PATH, d)\n",
      "  File \"<ipython-input-7-a0e1e0e6caa2>\", line 27, in build_inference_graph\n",
      "    name = ''\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 442, in import_graph_def\n",
      "    _ProcessNewOps(graph)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 234, in _ProcessNewOps\n",
      "    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in _add_new_tf_operations\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in <listcomp>\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3299, in _create_op_from_tf_operation\n",
      "    ret = Operation(c_op, self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n",
      "InvalidArgumentError (see above for traceback): Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:7' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:7\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:7\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:7\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:7\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:7\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:7\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 17\n",
      "Tensor(\"image_tensor:0\", shape=(?, ?, ?, 3), dtype=uint8, device=/device:GPU:0)\n",
      "['/device:GPU:0', '/device:GPU:1', '/device:GPU:2', '/device:GPU:3', '/device:GPU:4', '/device:GPU:5', '/device:GPU:6', '/device:GPU:7']\n",
      "Tensor(\"image_tensor:0\", shape=(?, ?, ?, 3), dtype=uint8, device=/device:GPU:1)\n",
      "['/device:GPU:0', '/device:GPU:1', '/device:GPU:2', '/device:GPU:3', '/device:GPU:4', '/device:GPU:5', '/device:GPU:6', '/device:GPU:7']\n",
      "Tensor(\"image_tensor:0\", shape=(?, ?, ?, 3), dtype=uint8, device=/device:GPU:2)\n",
      "['/device:GPU:0', '/device:GPU:1', '/device:GPU:2', '/device:GPU:3', '/device:GPU:4', '/device:GPU:5', '/device:GPU:6', '/device:GPU:7']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-20:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1334, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1317, in _run_fn\n",
      "    self._extend_graph()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1352, in _extend_graph\n",
      "    tf_session.ExtendSession(self._session)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:0\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:0\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:0\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:0\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:0\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[{{node Preprocessor/map/TensorArray_2}} = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:0\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-9-04675268f0aa>\", line 5, in threaded_inference\n",
      "    output_dict = sess.run(tensor_dict, feed_dict = {image_tensor: image})\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 929, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1152, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1328, in _do_run\n",
      "    run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1348, in _do_call\n",
      "    raise type(e)(node_def, op, message)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:0\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:0\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:0\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:0\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:0\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:0\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "Caused by op 'Preprocessor/map/TensorArray_2', defined at:\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 1431, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 346, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1080, in __init__\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-1d8adc307096>\", line 18, in <module>\n",
      "    tensors, graph = build_inference_graph(INFERENCE_GRAPH_PATH, d)\n",
      "  File \"<ipython-input-7-a0e1e0e6caa2>\", line 27, in build_inference_graph\n",
      "    name = ''\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 442, in import_graph_def\n",
      "    _ProcessNewOps(graph)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 234, in _ProcessNewOps\n",
      "    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in _add_new_tf_operations\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in <listcomp>\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3299, in _create_op_from_tf_operation\n",
      "    ret = Operation(c_op, self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n",
      "InvalidArgumentError (see above for traceback): Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:0\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:0\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:0\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:0\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:0\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:0\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "\n",
      "Exception in thread Thread-21:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1334, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1317, in _run_fn\n",
      "    self._extend_graph()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1352, in _extend_graph\n",
      "    tf_session.ExtendSession(self._session)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:1' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:1\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:1\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:1\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:1\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:1\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[{{node Preprocessor/map/TensorArray_2}} = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:1\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-9-04675268f0aa>\", line 5, in threaded_inference\n",
      "    output_dict = sess.run(tensor_dict, feed_dict = {image_tensor: image})\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 929, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1152, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1328, in _do_run\n",
      "    run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1348, in _do_call\n",
      "    raise type(e)(node_def, op, message)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:1' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:1\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:1\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:1\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:1\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:1\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:1\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "Caused by op 'Preprocessor/map/TensorArray_2', defined at:\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 1431, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 346, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1080, in __init__\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-1d8adc307096>\", line 18, in <module>\n",
      "    tensors, graph = build_inference_graph(INFERENCE_GRAPH_PATH, d)\n",
      "  File \"<ipython-input-7-a0e1e0e6caa2>\", line 27, in build_inference_graph\n",
      "    name = ''\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 442, in import_graph_def\n",
      "    _ProcessNewOps(graph)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 234, in _ProcessNewOps\n",
      "    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in _add_new_tf_operations\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in <listcomp>\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3299, in _create_op_from_tf_operation\n",
      "    ret = Operation(c_op, self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n",
      "InvalidArgumentError (see above for traceback): Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:1' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:1\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:1\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:1\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:1\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:1\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:1\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"image_tensor:0\", shape=(?, ?, ?, 3), dtype=uint8, device=/device:GPU:3)\n",
      "['/device:GPU:0', '/device:GPU:1', '/device:GPU:2', '/device:GPU:3', '/device:GPU:4', '/device:GPU:5', '/device:GPU:6', '/device:GPU:7']\n",
      "Tensor(\"image_tensor:0\", shape=(?, ?, ?, 3), dtype=uint8, device=/device:GPU:4)\n",
      "['/device:GPU:0', '/device:GPU:1', '/device:GPU:2', '/device:GPU:3', '/device:GPU:4', '/device:GPU:5', '/device:GPU:6', '/device:GPU:7']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-23:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1334, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1317, in _run_fn\n",
      "    self._extend_graph()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1352, in _extend_graph\n",
      "    tf_session.ExtendSession(self._session)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:3' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:3\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:3\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:3\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:3\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:3\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[{{node Preprocessor/map/TensorArray_2}} = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:3\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-9-04675268f0aa>\", line 5, in threaded_inference\n",
      "    output_dict = sess.run(tensor_dict, feed_dict = {image_tensor: image})\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 929, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1152, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1328, in _do_run\n",
      "    run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1348, in _do_call\n",
      "    raise type(e)(node_def, op, message)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:3' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:3\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:3\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:3\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:3\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:3\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:3\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "Caused by op 'Preprocessor/map/TensorArray_2', defined at:\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 1431, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 346, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1080, in __init__\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-1d8adc307096>\", line 18, in <module>\n",
      "    tensors, graph = build_inference_graph(INFERENCE_GRAPH_PATH, d)\n",
      "  File \"<ipython-input-7-a0e1e0e6caa2>\", line 27, in build_inference_graph\n",
      "    name = ''\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 442, in import_graph_def\n",
      "    _ProcessNewOps(graph)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 234, in _ProcessNewOps\n",
      "    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in _add_new_tf_operations\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in <listcomp>\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3299, in _create_op_from_tf_operation\n",
      "    ret = Operation(c_op, self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n",
      "InvalidArgumentError (see above for traceback): Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:3' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:3\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:3\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:3\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:3\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:3\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:3\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "\n",
      "Exception in thread Thread-22:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1334, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1317, in _run_fn\n",
      "    self._extend_graph()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1352, in _extend_graph\n",
      "    tf_session.ExtendSession(self._session)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:2' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:2\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:2\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:2\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:2\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:2\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[{{node Preprocessor/map/TensorArray_2}} = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:2\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-9-04675268f0aa>\", line 5, in threaded_inference\n",
      "    output_dict = sess.run(tensor_dict, feed_dict = {image_tensor: image})\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 929, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1152, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1328, in _do_run\n",
      "    run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1348, in _do_call\n",
      "    raise type(e)(node_def, op, message)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:2' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:2\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:2\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:2\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:2\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:2\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:2\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "Caused by op 'Preprocessor/map/TensorArray_2', defined at:\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 1431, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 346, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1080, in __init__\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-1d8adc307096>\", line 18, in <module>\n",
      "    tensors, graph = build_inference_graph(INFERENCE_GRAPH_PATH, d)\n",
      "  File \"<ipython-input-7-a0e1e0e6caa2>\", line 27, in build_inference_graph\n",
      "    name = ''\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 442, in import_graph_def\n",
      "    _ProcessNewOps(graph)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 234, in _ProcessNewOps\n",
      "    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in _add_new_tf_operations\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in <listcomp>\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3299, in _create_op_from_tf_operation\n",
      "    ret = Operation(c_op, self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n",
      "InvalidArgumentError (see above for traceback): Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:2' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:2\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:2\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:2\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:2\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:2\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:2\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"image_tensor:0\", shape=(?, ?, ?, 3), dtype=uint8, device=/device:GPU:5)\n",
      "['/device:GPU:0', '/device:GPU:1', '/device:GPU:2', '/device:GPU:3', '/device:GPU:4', '/device:GPU:5', '/device:GPU:6', '/device:GPU:7']\n",
      "Tensor(\"image_tensor:0\", shape=(?, ?, ?, 3), dtype=uint8, device=/device:GPU:6)\n",
      "['/device:GPU:0', '/device:GPU:1', '/device:GPU:2', '/device:GPU:3', '/device:GPU:4', '/device:GPU:5', '/device:GPU:6', '/device:GPU:7']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-25:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1334, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1317, in _run_fn\n",
      "    self._extend_graph()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1352, in _extend_graph\n",
      "    tf_session.ExtendSession(self._session)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:5' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:5\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:5\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:5\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:5\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:5\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[{{node Preprocessor/map/TensorArray_2}} = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:5\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-9-04675268f0aa>\", line 5, in threaded_inference\n",
      "    output_dict = sess.run(tensor_dict, feed_dict = {image_tensor: image})\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 929, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1152, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1328, in _do_run\n",
      "    run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1348, in _do_call\n",
      "    raise type(e)(node_def, op, message)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:5' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:5\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:5\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:5\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:5\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:5\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:5\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "Caused by op 'Preprocessor/map/TensorArray_2', defined at:\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 1431, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 346, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1080, in __init__\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-1d8adc307096>\", line 18, in <module>\n",
      "    tensors, graph = build_inference_graph(INFERENCE_GRAPH_PATH, d)\n",
      "  File \"<ipython-input-7-a0e1e0e6caa2>\", line 27, in build_inference_graph\n",
      "    name = ''\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 442, in import_graph_def\n",
      "    _ProcessNewOps(graph)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 234, in _ProcessNewOps\n",
      "    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in _add_new_tf_operations\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in <listcomp>\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3299, in _create_op_from_tf_operation\n",
      "    ret = Operation(c_op, self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n",
      "InvalidArgumentError (see above for traceback): Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:5' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:5\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:5\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:5\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:5\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:5\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:5\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "\n",
      "Exception in thread Thread-24:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1334, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1317, in _run_fn\n",
      "    self._extend_graph()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1352, in _extend_graph\n",
      "    tf_session.ExtendSession(self._session)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:4' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:4\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:4\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:4\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:4\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:4\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[{{node Preprocessor/map/TensorArray_2}} = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:4\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-9-04675268f0aa>\", line 5, in threaded_inference\n",
      "    output_dict = sess.run(tensor_dict, feed_dict = {image_tensor: image})\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 929, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1152, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1328, in _do_run\n",
      "    run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1348, in _do_call\n",
      "    raise type(e)(node_def, op, message)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:4' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:4\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:4\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:4\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:4\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:4\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:4\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "Caused by op 'Preprocessor/map/TensorArray_2', defined at:\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 1431, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 346, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1080, in __init__\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-1d8adc307096>\", line 18, in <module>\n",
      "    tensors, graph = build_inference_graph(INFERENCE_GRAPH_PATH, d)\n",
      "  File \"<ipython-input-7-a0e1e0e6caa2>\", line 27, in build_inference_graph\n",
      "    name = ''\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 442, in import_graph_def\n",
      "    _ProcessNewOps(graph)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 234, in _ProcessNewOps\n",
      "    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in _add_new_tf_operations\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in <listcomp>\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3299, in _create_op_from_tf_operation\n",
      "    ret = Operation(c_op, self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n",
      "InvalidArgumentError (see above for traceback): Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:4' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:4\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:4\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:4\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:4\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:4\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:4\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "\n",
      "Exception in thread Thread-26:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1334, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1317, in _run_fn\n",
      "    self._extend_graph()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1352, in _extend_graph\n",
      "    tf_session.ExtendSession(self._session)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:6' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:6\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:6\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:6\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:6\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:6\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[{{node Preprocessor/map/TensorArray_2}} = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:6\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-9-04675268f0aa>\", line 5, in threaded_inference\n",
      "    output_dict = sess.run(tensor_dict, feed_dict = {image_tensor: image})\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 929, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1152, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1328, in _do_run\n",
      "    run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1348, in _do_call\n",
      "    raise type(e)(node_def, op, message)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:6' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:6\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:6\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:6\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:6\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:6\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:6\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "Caused by op 'Preprocessor/map/TensorArray_2', defined at:\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 1431, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 346, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1080, in __init__\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-1d8adc307096>\", line 18, in <module>\n",
      "    tensors, graph = build_inference_graph(INFERENCE_GRAPH_PATH, d)\n",
      "  File \"<ipython-input-7-a0e1e0e6caa2>\", line 27, in build_inference_graph\n",
      "    name = ''\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 442, in import_graph_def\n",
      "    _ProcessNewOps(graph)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 234, in _ProcessNewOps\n",
      "    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in _add_new_tf_operations\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in <listcomp>\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3299, in _create_op_from_tf_operation\n",
      "    ret = Operation(c_op, self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n",
      "InvalidArgumentError (see above for traceback): Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:6' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:6\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:6\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:6\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:6\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:6\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:6\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"image_tensor:0\", shape=(?, ?, ?, 3), dtype=uint8, device=/device:GPU:7)\n",
      "['/device:GPU:0', '/device:GPU:1', '/device:GPU:2', '/device:GPU:3', '/device:GPU:4', '/device:GPU:5', '/device:GPU:6', '/device:GPU:7']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-27:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1334, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1317, in _run_fn\n",
      "    self._extend_graph()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1352, in _extend_graph\n",
      "    tf_session.ExtendSession(self._session)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:7' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:7\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:7\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:7\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:7\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:7\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[{{node Preprocessor/map/TensorArray_2}} = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:7\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-9-04675268f0aa>\", line 5, in threaded_inference\n",
      "    output_dict = sess.run(tensor_dict, feed_dict = {image_tensor: image})\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 929, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1152, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1328, in _do_run\n",
      "    run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1348, in _do_call\n",
      "    raise type(e)(node_def, op, message)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:7' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:7\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:7\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:7\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:7\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:7\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:7\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "Caused by op 'Preprocessor/map/TensorArray_2', defined at:\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 1431, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 346, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1080, in __init__\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-1d8adc307096>\", line 18, in <module>\n",
      "    tensors, graph = build_inference_graph(INFERENCE_GRAPH_PATH, d)\n",
      "  File \"<ipython-input-7-a0e1e0e6caa2>\", line 27, in build_inference_graph\n",
      "    name = ''\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 442, in import_graph_def\n",
      "    _ProcessNewOps(graph)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 234, in _ProcessNewOps\n",
      "    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in _add_new_tf_operations\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in <listcomp>\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3299, in _create_op_from_tf_operation\n",
      "    ret = Operation(c_op, self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n",
      "InvalidArgumentError (see above for traceback): Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:7' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:7\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:7\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:7\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:7\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:7\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:7\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 25\n",
      "Tensor(\"image_tensor:0\", shape=(?, ?, ?, 3), dtype=uint8, device=/device:GPU:0)\n",
      "['/device:GPU:0', '/device:GPU:1', '/device:GPU:2', '/device:GPU:3', '/device:GPU:4', '/device:GPU:5', '/device:GPU:6', '/device:GPU:7']\n",
      "Tensor(\"image_tensor:0\", shape=(?, ?, ?, 3), dtype=uint8, device=/device:GPU:1)\n",
      "['/device:GPU:0', '/device:GPU:1', '/device:GPU:2', '/device:GPU:3', '/device:GPU:4', '/device:GPU:5', '/device:GPU:6', '/device:GPU:7']\n",
      "Tensor(\"image_tensor:0\", shape=(?, ?, ?, 3), dtype=uint8, device=/device:GPU:2)\n",
      "['/device:GPU:0', '/device:GPU:1', '/device:GPU:2', '/device:GPU:3', '/device:GPU:4', '/device:GPU:5', '/device:GPU:6', '/device:GPU:7']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-28:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1334, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1317, in _run_fn\n",
      "    self._extend_graph()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1352, in _extend_graph\n",
      "    tf_session.ExtendSession(self._session)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:0\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:0\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:0\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:0\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:0\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[{{node Preprocessor/map/TensorArray_2}} = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:0\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-9-04675268f0aa>\", line 5, in threaded_inference\n",
      "    output_dict = sess.run(tensor_dict, feed_dict = {image_tensor: image})\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 929, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1152, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1328, in _do_run\n",
      "    run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1348, in _do_call\n",
      "    raise type(e)(node_def, op, message)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:0\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:0\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:0\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:0\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:0\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:0\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "Caused by op 'Preprocessor/map/TensorArray_2', defined at:\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 1431, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 346, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1080, in __init__\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-1d8adc307096>\", line 18, in <module>\n",
      "    tensors, graph = build_inference_graph(INFERENCE_GRAPH_PATH, d)\n",
      "  File \"<ipython-input-7-a0e1e0e6caa2>\", line 27, in build_inference_graph\n",
      "    name = ''\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 442, in import_graph_def\n",
      "    _ProcessNewOps(graph)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 234, in _ProcessNewOps\n",
      "    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in _add_new_tf_operations\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in <listcomp>\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3299, in _create_op_from_tf_operation\n",
      "    ret = Operation(c_op, self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n",
      "InvalidArgumentError (see above for traceback): Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:0\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:0\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:0\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:0\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:0\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:0\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "\n",
      "Exception in thread Thread-29:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1334, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1317, in _run_fn\n",
      "    self._extend_graph()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1352, in _extend_graph\n",
      "    tf_session.ExtendSession(self._session)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:1' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:1\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:1\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:1\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:1\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:1\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[{{node Preprocessor/map/TensorArray_2}} = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:1\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-9-04675268f0aa>\", line 5, in threaded_inference\n",
      "    output_dict = sess.run(tensor_dict, feed_dict = {image_tensor: image})\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 929, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1152, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1328, in _do_run\n",
      "    run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1348, in _do_call\n",
      "    raise type(e)(node_def, op, message)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:1' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:1\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:1\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:1\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:1\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:1\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:1\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "Caused by op 'Preprocessor/map/TensorArray_2', defined at:\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 1431, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 346, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1080, in __init__\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-1d8adc307096>\", line 18, in <module>\n",
      "    tensors, graph = build_inference_graph(INFERENCE_GRAPH_PATH, d)\n",
      "  File \"<ipython-input-7-a0e1e0e6caa2>\", line 27, in build_inference_graph\n",
      "    name = ''\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 442, in import_graph_def\n",
      "    _ProcessNewOps(graph)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 234, in _ProcessNewOps\n",
      "    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in _add_new_tf_operations\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in <listcomp>\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3299, in _create_op_from_tf_operation\n",
      "    ret = Operation(c_op, self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n",
      "InvalidArgumentError (see above for traceback): Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:1' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:1\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:1\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:1\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:1\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:1\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:1\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"image_tensor:0\", shape=(?, ?, ?, 3), dtype=uint8, device=/device:GPU:3)\n",
      "['/device:GPU:0', '/device:GPU:1', '/device:GPU:2', '/device:GPU:3', '/device:GPU:4', '/device:GPU:5', '/device:GPU:6', '/device:GPU:7']\n",
      "Tensor(\"image_tensor:0\", shape=(?, ?, ?, 3), dtype=uint8, device=/device:GPU:4)\n",
      "['/device:GPU:0', '/device:GPU:1', '/device:GPU:2', '/device:GPU:3', '/device:GPU:4', '/device:GPU:5', '/device:GPU:6', '/device:GPU:7']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-30:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1334, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1317, in _run_fn\n",
      "    self._extend_graph()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1352, in _extend_graph\n",
      "    tf_session.ExtendSession(self._session)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:2' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:2\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:2\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:2\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:2\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:2\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[{{node Preprocessor/map/TensorArray_2}} = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:2\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-9-04675268f0aa>\", line 5, in threaded_inference\n",
      "    output_dict = sess.run(tensor_dict, feed_dict = {image_tensor: image})\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 929, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1152, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1328, in _do_run\n",
      "    run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1348, in _do_call\n",
      "    raise type(e)(node_def, op, message)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:2' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:2\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:2\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:2\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:2\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:2\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:2\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "Caused by op 'Preprocessor/map/TensorArray_2', defined at:\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 1431, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 346, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1080, in __init__\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-1d8adc307096>\", line 18, in <module>\n",
      "    tensors, graph = build_inference_graph(INFERENCE_GRAPH_PATH, d)\n",
      "  File \"<ipython-input-7-a0e1e0e6caa2>\", line 27, in build_inference_graph\n",
      "    name = ''\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 442, in import_graph_def\n",
      "    _ProcessNewOps(graph)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 234, in _ProcessNewOps\n",
      "    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in _add_new_tf_operations\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in <listcomp>\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3299, in _create_op_from_tf_operation\n",
      "    ret = Operation(c_op, self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n",
      "InvalidArgumentError (see above for traceback): Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:2' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:2\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:2\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:2\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:2\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:2\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:2\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"image_tensor:0\", shape=(?, ?, ?, 3), dtype=uint8, device=/device:GPU:5)\n",
      "['/device:GPU:0', '/device:GPU:1', '/device:GPU:2', '/device:GPU:3', '/device:GPU:4', '/device:GPU:5', '/device:GPU:6', '/device:GPU:7']\n",
      "Tensor(\"image_tensor:0\", shape=(?, ?, ?, 3), dtype=uint8, device=/device:GPU:6)\n",
      "['/device:GPU:0', '/device:GPU:1', '/device:GPU:2', '/device:GPU:3', '/device:GPU:4', '/device:GPU:5', '/device:GPU:6', '/device:GPU:7']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-32:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1334, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1317, in _run_fn\n",
      "    self._extend_graph()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1352, in _extend_graph\n",
      "    tf_session.ExtendSession(self._session)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:4' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:4\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:4\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:4\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:4\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:4\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[{{node Preprocessor/map/TensorArray_2}} = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:4\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-9-04675268f0aa>\", line 5, in threaded_inference\n",
      "    output_dict = sess.run(tensor_dict, feed_dict = {image_tensor: image})\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 929, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1152, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1328, in _do_run\n",
      "    run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1348, in _do_call\n",
      "    raise type(e)(node_def, op, message)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:4' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:4\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:4\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:4\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:4\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:4\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:4\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "Caused by op 'Preprocessor/map/TensorArray_2', defined at:\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 1431, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 346, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1080, in __init__\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-1d8adc307096>\", line 18, in <module>\n",
      "    tensors, graph = build_inference_graph(INFERENCE_GRAPH_PATH, d)\n",
      "  File \"<ipython-input-7-a0e1e0e6caa2>\", line 27, in build_inference_graph\n",
      "    name = ''\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 442, in import_graph_def\n",
      "    _ProcessNewOps(graph)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 234, in _ProcessNewOps\n",
      "    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in _add_new_tf_operations\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in <listcomp>\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3299, in _create_op_from_tf_operation\n",
      "    ret = Operation(c_op, self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n",
      "InvalidArgumentError (see above for traceback): Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:4' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:4\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:4\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:4\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:4\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:4\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:4\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "\n",
      "Exception in thread Thread-31:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1334, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1317, in _run_fn\n",
      "    self._extend_graph()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1352, in _extend_graph\n",
      "    tf_session.ExtendSession(self._session)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:3' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:3\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:3\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:3\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:3\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:3\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[{{node Preprocessor/map/TensorArray_2}} = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:3\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-9-04675268f0aa>\", line 5, in threaded_inference\n",
      "    output_dict = sess.run(tensor_dict, feed_dict = {image_tensor: image})\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 929, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1152, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1328, in _do_run\n",
      "    run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1348, in _do_call\n",
      "    raise type(e)(node_def, op, message)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:3' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:3\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:3\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:3\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:3\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:3\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:3\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "Caused by op 'Preprocessor/map/TensorArray_2', defined at:\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 1431, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 346, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1080, in __init__\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-1d8adc307096>\", line 18, in <module>\n",
      "    tensors, graph = build_inference_graph(INFERENCE_GRAPH_PATH, d)\n",
      "  File \"<ipython-input-7-a0e1e0e6caa2>\", line 27, in build_inference_graph\n",
      "    name = ''\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 442, in import_graph_def\n",
      "    _ProcessNewOps(graph)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 234, in _ProcessNewOps\n",
      "    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in _add_new_tf_operations\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in <listcomp>\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3299, in _create_op_from_tf_operation\n",
      "    ret = Operation(c_op, self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n",
      "InvalidArgumentError (see above for traceback): Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:3' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:3\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:3\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:3\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:3\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:3\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:3\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"image_tensor:0\", shape=(?, ?, ?, 3), dtype=uint8, device=/device:GPU:7)\n",
      "['/device:GPU:0', '/device:GPU:1', '/device:GPU:2', '/device:GPU:3', '/device:GPU:4', '/device:GPU:5', '/device:GPU:6', '/device:GPU:7']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-34:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1334, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1317, in _run_fn\n",
      "    self._extend_graph()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1352, in _extend_graph\n",
      "    tf_session.ExtendSession(self._session)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:6' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:6\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:6\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:6\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:6\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:6\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[{{node Preprocessor/map/TensorArray_2}} = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:6\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-9-04675268f0aa>\", line 5, in threaded_inference\n",
      "    output_dict = sess.run(tensor_dict, feed_dict = {image_tensor: image})\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 929, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1152, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1328, in _do_run\n",
      "    run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1348, in _do_call\n",
      "    raise type(e)(node_def, op, message)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:6' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:6\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:6\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:6\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:6\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:6\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:6\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "Caused by op 'Preprocessor/map/TensorArray_2', defined at:\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 1431, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 346, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1080, in __init__\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-1d8adc307096>\", line 18, in <module>\n",
      "    tensors, graph = build_inference_graph(INFERENCE_GRAPH_PATH, d)\n",
      "  File \"<ipython-input-7-a0e1e0e6caa2>\", line 27, in build_inference_graph\n",
      "    name = ''\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 442, in import_graph_def\n",
      "    _ProcessNewOps(graph)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 234, in _ProcessNewOps\n",
      "    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in _add_new_tf_operations\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in <listcomp>\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3299, in _create_op_from_tf_operation\n",
      "    ret = Operation(c_op, self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n",
      "InvalidArgumentError (see above for traceback): Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:6' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:6\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:6\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:6\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:6\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:6\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:6\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "\n",
      "Exception in thread Thread-33:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1334, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1317, in _run_fn\n",
      "    self._extend_graph()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1352, in _extend_graph\n",
      "    tf_session.ExtendSession(self._session)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:5' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:5\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:5\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:5\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:5\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:5\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[{{node Preprocessor/map/TensorArray_2}} = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:5\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-9-04675268f0aa>\", line 5, in threaded_inference\n",
      "    output_dict = sess.run(tensor_dict, feed_dict = {image_tensor: image})\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 929, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1152, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1328, in _do_run\n",
      "    run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1348, in _do_call\n",
      "    raise type(e)(node_def, op, message)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:5' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:5\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:5\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:5\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:5\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:5\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:5\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "Caused by op 'Preprocessor/map/TensorArray_2', defined at:\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 1431, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 346, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1080, in __init__\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-1d8adc307096>\", line 18, in <module>\n",
      "    tensors, graph = build_inference_graph(INFERENCE_GRAPH_PATH, d)\n",
      "  File \"<ipython-input-7-a0e1e0e6caa2>\", line 27, in build_inference_graph\n",
      "    name = ''\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 442, in import_graph_def\n",
      "    _ProcessNewOps(graph)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 234, in _ProcessNewOps\n",
      "    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in _add_new_tf_operations\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in <listcomp>\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3299, in _create_op_from_tf_operation\n",
      "    ret = Operation(c_op, self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n",
      "InvalidArgumentError (see above for traceback): Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:5' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:5\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:5\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:5\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:5\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:5\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:5\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "\n",
      "Exception in thread Thread-35:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1334, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1317, in _run_fn\n",
      "    self._extend_graph()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1352, in _extend_graph\n",
      "    tf_session.ExtendSession(self._session)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:7' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:7\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:7\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:7\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:7\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:7\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[{{node Preprocessor/map/TensorArray_2}} = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:7\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-9-04675268f0aa>\", line 5, in threaded_inference\n",
      "    output_dict = sess.run(tensor_dict, feed_dict = {image_tensor: image})\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 929, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1152, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1328, in _do_run\n",
      "    run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1348, in _do_call\n",
      "    raise type(e)(node_def, op, message)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:7' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:7\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:7\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:7\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:7\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:7\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:7\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "Caused by op 'Preprocessor/map/TensorArray_2', defined at:\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 1431, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 346, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1080, in __init__\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-1d8adc307096>\", line 18, in <module>\n",
      "    tensors, graph = build_inference_graph(INFERENCE_GRAPH_PATH, d)\n",
      "  File \"<ipython-input-7-a0e1e0e6caa2>\", line 27, in build_inference_graph\n",
      "    name = ''\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 442, in import_graph_def\n",
      "    _ProcessNewOps(graph)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 234, in _ProcessNewOps\n",
      "    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in _add_new_tf_operations\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in <listcomp>\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3299, in _create_op_from_tf_operation\n",
      "    ret = Operation(c_op, self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n",
      "InvalidArgumentError (see above for traceback): Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:7' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:7\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:7\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:7\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:7\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:7\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:7\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 33\n",
      "Tensor(\"image_tensor:0\", shape=(?, ?, ?, 3), dtype=uint8, device=/device:GPU:0)\n",
      "['/device:GPU:0', '/device:GPU:1', '/device:GPU:2', '/device:GPU:3', '/device:GPU:4', '/device:GPU:5', '/device:GPU:6', '/device:GPU:7']\n",
      "Tensor(\"image_tensor:0\", shape=(?, ?, ?, 3), dtype=uint8, device=/device:GPU:1)\n",
      "['/device:GPU:0', '/device:GPU:1', '/device:GPU:2', '/device:GPU:3', '/device:GPU:4', '/device:GPU:5', '/device:GPU:6', '/device:GPU:7']\n",
      "Tensor(\"image_tensor:0\", shape=(?, ?, ?, 3), dtype=uint8, device=/device:GPU:2)\n",
      "['/device:GPU:0', '/device:GPU:1', '/device:GPU:2', '/device:GPU:3', '/device:GPU:4', '/device:GPU:5', '/device:GPU:6', '/device:GPU:7']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-36:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1334, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1317, in _run_fn\n",
      "    self._extend_graph()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1352, in _extend_graph\n",
      "    tf_session.ExtendSession(self._session)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:0\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:0\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:0\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:0\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:0\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[{{node Preprocessor/map/TensorArray_2}} = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:0\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-9-04675268f0aa>\", line 5, in threaded_inference\n",
      "    output_dict = sess.run(tensor_dict, feed_dict = {image_tensor: image})\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 929, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1152, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1328, in _do_run\n",
      "    run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1348, in _do_call\n",
      "    raise type(e)(node_def, op, message)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:0\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:0\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:0\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:0\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:0\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:0\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "Caused by op 'Preprocessor/map/TensorArray_2', defined at:\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 1431, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 346, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1080, in __init__\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-1d8adc307096>\", line 18, in <module>\n",
      "    tensors, graph = build_inference_graph(INFERENCE_GRAPH_PATH, d)\n",
      "  File \"<ipython-input-7-a0e1e0e6caa2>\", line 27, in build_inference_graph\n",
      "    name = ''\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 442, in import_graph_def\n",
      "    _ProcessNewOps(graph)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 234, in _ProcessNewOps\n",
      "    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in _add_new_tf_operations\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in <listcomp>\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3299, in _create_op_from_tf_operation\n",
      "    ret = Operation(c_op, self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n",
      "InvalidArgumentError (see above for traceback): Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:0\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:0\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:0\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:0\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:0\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:0\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "\n",
      "Exception in thread Thread-37:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1334, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1317, in _run_fn\n",
      "    self._extend_graph()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1352, in _extend_graph\n",
      "    tf_session.ExtendSession(self._session)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:1' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:1\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:1\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:1\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:1\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:1\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[{{node Preprocessor/map/TensorArray_2}} = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:1\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-9-04675268f0aa>\", line 5, in threaded_inference\n",
      "    output_dict = sess.run(tensor_dict, feed_dict = {image_tensor: image})\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 929, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1152, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1328, in _do_run\n",
      "    run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1348, in _do_call\n",
      "    raise type(e)(node_def, op, message)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:1' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:1\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:1\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:1\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:1\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:1\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:1\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "Caused by op 'Preprocessor/map/TensorArray_2', defined at:\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 1431, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 346, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1080, in __init__\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-1d8adc307096>\", line 18, in <module>\n",
      "    tensors, graph = build_inference_graph(INFERENCE_GRAPH_PATH, d)\n",
      "  File \"<ipython-input-7-a0e1e0e6caa2>\", line 27, in build_inference_graph\n",
      "    name = ''\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 442, in import_graph_def\n",
      "    _ProcessNewOps(graph)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 234, in _ProcessNewOps\n",
      "    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in _add_new_tf_operations\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in <listcomp>\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3299, in _create_op_from_tf_operation\n",
      "    ret = Operation(c_op, self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n",
      "InvalidArgumentError (see above for traceback): Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:1' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:1\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:1\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:1\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:1\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:1\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:1\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"image_tensor:0\", shape=(?, ?, ?, 3), dtype=uint8, device=/device:GPU:3)\n",
      "['/device:GPU:0', '/device:GPU:1', '/device:GPU:2', '/device:GPU:3', '/device:GPU:4', '/device:GPU:5', '/device:GPU:6', '/device:GPU:7']\n",
      "Tensor(\"image_tensor:0\", shape=(?, ?, ?, 3), dtype=uint8, device=/device:GPU:4)\n",
      "['/device:GPU:0', '/device:GPU:1', '/device:GPU:2', '/device:GPU:3', '/device:GPU:4', '/device:GPU:5', '/device:GPU:6', '/device:GPU:7']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-38:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1334, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1317, in _run_fn\n",
      "    self._extend_graph()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1352, in _extend_graph\n",
      "    tf_session.ExtendSession(self._session)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:2' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:2\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:2\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:2\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:2\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:2\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[{{node Preprocessor/map/TensorArray_2}} = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:2\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-9-04675268f0aa>\", line 5, in threaded_inference\n",
      "    output_dict = sess.run(tensor_dict, feed_dict = {image_tensor: image})\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 929, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1152, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1328, in _do_run\n",
      "    run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1348, in _do_call\n",
      "    raise type(e)(node_def, op, message)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:2' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:2\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:2\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:2\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:2\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:2\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:2\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "Caused by op 'Preprocessor/map/TensorArray_2', defined at:\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 1431, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 346, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1080, in __init__\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-1d8adc307096>\", line 18, in <module>\n",
      "    tensors, graph = build_inference_graph(INFERENCE_GRAPH_PATH, d)\n",
      "  File \"<ipython-input-7-a0e1e0e6caa2>\", line 27, in build_inference_graph\n",
      "    name = ''\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 442, in import_graph_def\n",
      "    _ProcessNewOps(graph)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 234, in _ProcessNewOps\n",
      "    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in _add_new_tf_operations\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in <listcomp>\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3299, in _create_op_from_tf_operation\n",
      "    ret = Operation(c_op, self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n",
      "InvalidArgumentError (see above for traceback): Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:2' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:2\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:2\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:2\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:2\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:2\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:2\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"image_tensor:0\", shape=(?, ?, ?, 3), dtype=uint8, device=/device:GPU:5)\n",
      "['/device:GPU:0', '/device:GPU:1', '/device:GPU:2', '/device:GPU:3', '/device:GPU:4', '/device:GPU:5', '/device:GPU:6', '/device:GPU:7']\n",
      "Tensor(\"image_tensor:0\", shape=(?, ?, ?, 3), dtype=uint8, device=/device:GPU:6)\n",
      "['/device:GPU:0', '/device:GPU:1', '/device:GPU:2', '/device:GPU:3', '/device:GPU:4', '/device:GPU:5', '/device:GPU:6', '/device:GPU:7']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-40:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1334, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1317, in _run_fn\n",
      "    self._extend_graph()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1352, in _extend_graph\n",
      "    tf_session.ExtendSession(self._session)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:4' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:4\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:4\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:4\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:4\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:4\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[{{node Preprocessor/map/TensorArray_2}} = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:4\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-9-04675268f0aa>\", line 5, in threaded_inference\n",
      "    output_dict = sess.run(tensor_dict, feed_dict = {image_tensor: image})\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 929, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1152, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1328, in _do_run\n",
      "    run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1348, in _do_call\n",
      "    raise type(e)(node_def, op, message)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:4' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:4\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:4\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:4\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:4\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:4\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:4\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "Caused by op 'Preprocessor/map/TensorArray_2', defined at:\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 1431, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 346, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1080, in __init__\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-1d8adc307096>\", line 18, in <module>\n",
      "    tensors, graph = build_inference_graph(INFERENCE_GRAPH_PATH, d)\n",
      "  File \"<ipython-input-7-a0e1e0e6caa2>\", line 27, in build_inference_graph\n",
      "    name = ''\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 442, in import_graph_def\n",
      "    _ProcessNewOps(graph)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 234, in _ProcessNewOps\n",
      "    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in _add_new_tf_operations\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in <listcomp>\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3299, in _create_op_from_tf_operation\n",
      "    ret = Operation(c_op, self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n",
      "InvalidArgumentError (see above for traceback): Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:4' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:4\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:4\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:4\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:4\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:4\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:4\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "\n",
      "Exception in thread Thread-39:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1334, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1317, in _run_fn\n",
      "    self._extend_graph()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1352, in _extend_graph\n",
      "    tf_session.ExtendSession(self._session)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:3' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:3\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:3\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:3\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:3\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:3\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[{{node Preprocessor/map/TensorArray_2}} = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:3\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-9-04675268f0aa>\", line 5, in threaded_inference\n",
      "    output_dict = sess.run(tensor_dict, feed_dict = {image_tensor: image})\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 929, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1152, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1328, in _do_run\n",
      "    run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1348, in _do_call\n",
      "    raise type(e)(node_def, op, message)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:3' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:3\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:3\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:3\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:3\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:3\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:3\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "Caused by op 'Preprocessor/map/TensorArray_2', defined at:\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 1431, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 346, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1080, in __init__\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-1d8adc307096>\", line 18, in <module>\n",
      "    tensors, graph = build_inference_graph(INFERENCE_GRAPH_PATH, d)\n",
      "  File \"<ipython-input-7-a0e1e0e6caa2>\", line 27, in build_inference_graph\n",
      "    name = ''\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 442, in import_graph_def\n",
      "    _ProcessNewOps(graph)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 234, in _ProcessNewOps\n",
      "    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in _add_new_tf_operations\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in <listcomp>\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3299, in _create_op_from_tf_operation\n",
      "    ret = Operation(c_op, self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n",
      "InvalidArgumentError (see above for traceback): Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:3' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:3\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:3\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:3\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:3\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:3\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:3\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"image_tensor:0\", shape=(?, ?, ?, 3), dtype=uint8, device=/device:GPU:7)\n",
      "['/device:GPU:0', '/device:GPU:1', '/device:GPU:2', '/device:GPU:3', '/device:GPU:4', '/device:GPU:5', '/device:GPU:6', '/device:GPU:7']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-41:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1334, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1317, in _run_fn\n",
      "    self._extend_graph()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1352, in _extend_graph\n",
      "    tf_session.ExtendSession(self._session)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:5' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:5\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:5\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:5\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:5\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:5\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[{{node Preprocessor/map/TensorArray_2}} = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:5\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-9-04675268f0aa>\", line 5, in threaded_inference\n",
      "    output_dict = sess.run(tensor_dict, feed_dict = {image_tensor: image})\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 929, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1152, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1328, in _do_run\n",
      "    run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1348, in _do_call\n",
      "    raise type(e)(node_def, op, message)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:5' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:5\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:5\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:5\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:5\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:5\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:5\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "Caused by op 'Preprocessor/map/TensorArray_2', defined at:\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 1431, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 346, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1080, in __init__\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-1d8adc307096>\", line 18, in <module>\n",
      "    tensors, graph = build_inference_graph(INFERENCE_GRAPH_PATH, d)\n",
      "  File \"<ipython-input-7-a0e1e0e6caa2>\", line 27, in build_inference_graph\n",
      "    name = ''\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 442, in import_graph_def\n",
      "    _ProcessNewOps(graph)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 234, in _ProcessNewOps\n",
      "    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in _add_new_tf_operations\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in <listcomp>\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3299, in _create_op_from_tf_operation\n",
      "    ret = Operation(c_op, self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n",
      "InvalidArgumentError (see above for traceback): Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:5' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:5\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:5\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:5\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:5\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:5\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:5\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "\n",
      "Exception in thread Thread-42:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1334, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1317, in _run_fn\n",
      "    self._extend_graph()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1352, in _extend_graph\n",
      "    tf_session.ExtendSession(self._session)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:6' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:6\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:6\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:6\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:6\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:6\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[{{node Preprocessor/map/TensorArray_2}} = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:6\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-9-04675268f0aa>\", line 5, in threaded_inference\n",
      "    output_dict = sess.run(tensor_dict, feed_dict = {image_tensor: image})\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 929, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1152, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1328, in _do_run\n",
      "    run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1348, in _do_call\n",
      "    raise type(e)(node_def, op, message)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:6' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:6\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:6\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:6\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:6\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:6\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:6\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "Caused by op 'Preprocessor/map/TensorArray_2', defined at:\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 1431, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 346, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1080, in __init__\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-1d8adc307096>\", line 18, in <module>\n",
      "    tensors, graph = build_inference_graph(INFERENCE_GRAPH_PATH, d)\n",
      "  File \"<ipython-input-7-a0e1e0e6caa2>\", line 27, in build_inference_graph\n",
      "    name = ''\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 442, in import_graph_def\n",
      "    _ProcessNewOps(graph)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 234, in _ProcessNewOps\n",
      "    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in _add_new_tf_operations\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in <listcomp>\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3299, in _create_op_from_tf_operation\n",
      "    ret = Operation(c_op, self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n",
      "InvalidArgumentError (see above for traceback): Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:6' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:6\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:6\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:6\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:6\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:6\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:6\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "\n",
      "Exception in thread Thread-43:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1334, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1317, in _run_fn\n",
      "    self._extend_graph()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1352, in _extend_graph\n",
      "    tf_session.ExtendSession(self._session)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:7' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:7\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:7\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:7\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:7\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:7\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[{{node Preprocessor/map/TensorArray_2}} = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:7\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-9-04675268f0aa>\", line 5, in threaded_inference\n",
      "    output_dict = sess.run(tensor_dict, feed_dict = {image_tensor: image})\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 929, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1152, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1328, in _do_run\n",
      "    run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1348, in _do_call\n",
      "    raise type(e)(node_def, op, message)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:7' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:7\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:7\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:7\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:7\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:7\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:7\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "Caused by op 'Preprocessor/map/TensorArray_2', defined at:\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 1431, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 346, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1080, in __init__\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-1d8adc307096>\", line 18, in <module>\n",
      "    tensors, graph = build_inference_graph(INFERENCE_GRAPH_PATH, d)\n",
      "  File \"<ipython-input-7-a0e1e0e6caa2>\", line 27, in build_inference_graph\n",
      "    name = ''\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 442, in import_graph_def\n",
      "    _ProcessNewOps(graph)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 234, in _ProcessNewOps\n",
      "    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in _add_new_tf_operations\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in <listcomp>\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3299, in _create_op_from_tf_operation\n",
      "    ret = Operation(c_op, self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n",
      "InvalidArgumentError (see above for traceback): Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:7' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:7\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:7\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:7\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:7\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:7\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:7\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 41\n",
      "Tensor(\"image_tensor:0\", shape=(?, ?, ?, 3), dtype=uint8, device=/device:GPU:0)\n",
      "['/device:GPU:0', '/device:GPU:1', '/device:GPU:2', '/device:GPU:3', '/device:GPU:4', '/device:GPU:5', '/device:GPU:6', '/device:GPU:7']\n",
      "Tensor(\"image_tensor:0\", shape=(?, ?, ?, 3), dtype=uint8, device=/device:GPU:1)\n",
      "['/device:GPU:0', '/device:GPU:1', '/device:GPU:2', '/device:GPU:3', '/device:GPU:4', '/device:GPU:5', '/device:GPU:6', '/device:GPU:7']\n",
      "Tensor(\"image_tensor:0\", shape=(?, ?, ?, 3), dtype=uint8, device=/device:GPU:2)\n",
      "['/device:GPU:0', '/device:GPU:1', '/device:GPU:2', '/device:GPU:3', '/device:GPU:4', '/device:GPU:5', '/device:GPU:6', '/device:GPU:7']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-44:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1334, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1317, in _run_fn\n",
      "    self._extend_graph()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1352, in _extend_graph\n",
      "    tf_session.ExtendSession(self._session)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:0\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:0\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:0\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:0\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:0\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[{{node Preprocessor/map/TensorArray_2}} = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:0\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-9-04675268f0aa>\", line 5, in threaded_inference\n",
      "    output_dict = sess.run(tensor_dict, feed_dict = {image_tensor: image})\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 929, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1152, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1328, in _do_run\n",
      "    run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1348, in _do_call\n",
      "    raise type(e)(node_def, op, message)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:0\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:0\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:0\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:0\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:0\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:0\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "Caused by op 'Preprocessor/map/TensorArray_2', defined at:\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 1431, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 346, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1080, in __init__\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-1d8adc307096>\", line 18, in <module>\n",
      "    tensors, graph = build_inference_graph(INFERENCE_GRAPH_PATH, d)\n",
      "  File \"<ipython-input-7-a0e1e0e6caa2>\", line 27, in build_inference_graph\n",
      "    name = ''\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 442, in import_graph_def\n",
      "    _ProcessNewOps(graph)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 234, in _ProcessNewOps\n",
      "    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in _add_new_tf_operations\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in <listcomp>\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3299, in _create_op_from_tf_operation\n",
      "    ret = Operation(c_op, self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n",
      "InvalidArgumentError (see above for traceback): Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:0\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:0\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:0\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:0\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:0\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:0\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "\n",
      "Exception in thread Thread-45:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1334, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1317, in _run_fn\n",
      "    self._extend_graph()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1352, in _extend_graph\n",
      "    tf_session.ExtendSession(self._session)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:1' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:1\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:1\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:1\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:1\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:1\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[{{node Preprocessor/map/TensorArray_2}} = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:1\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-9-04675268f0aa>\", line 5, in threaded_inference\n",
      "    output_dict = sess.run(tensor_dict, feed_dict = {image_tensor: image})\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 929, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1152, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1328, in _do_run\n",
      "    run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1348, in _do_call\n",
      "    raise type(e)(node_def, op, message)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:1' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:1\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:1\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:1\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:1\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:1\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:1\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "Caused by op 'Preprocessor/map/TensorArray_2', defined at:\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 1431, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 346, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1080, in __init__\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-1d8adc307096>\", line 18, in <module>\n",
      "    tensors, graph = build_inference_graph(INFERENCE_GRAPH_PATH, d)\n",
      "  File \"<ipython-input-7-a0e1e0e6caa2>\", line 27, in build_inference_graph\n",
      "    name = ''\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 442, in import_graph_def\n",
      "    _ProcessNewOps(graph)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 234, in _ProcessNewOps\n",
      "    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in _add_new_tf_operations\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in <listcomp>\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3299, in _create_op_from_tf_operation\n",
      "    ret = Operation(c_op, self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n",
      "InvalidArgumentError (see above for traceback): Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:1' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:1\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:1\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:1\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:1\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:1\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:1\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"image_tensor:0\", shape=(?, ?, ?, 3), dtype=uint8, device=/device:GPU:3)\n",
      "['/device:GPU:0', '/device:GPU:1', '/device:GPU:2', '/device:GPU:3', '/device:GPU:4', '/device:GPU:5', '/device:GPU:6', '/device:GPU:7']\n",
      "Tensor(\"image_tensor:0\", shape=(?, ?, ?, 3), dtype=uint8, device=/device:GPU:4)\n",
      "['/device:GPU:0', '/device:GPU:1', '/device:GPU:2', '/device:GPU:3', '/device:GPU:4', '/device:GPU:5', '/device:GPU:6', '/device:GPU:7']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-47:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1334, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1317, in _run_fn\n",
      "    self._extend_graph()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1352, in _extend_graph\n",
      "    tf_session.ExtendSession(self._session)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:3' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:3\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:3\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:3\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:3\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:3\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[{{node Preprocessor/map/TensorArray_2}} = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:3\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-9-04675268f0aa>\", line 5, in threaded_inference\n",
      "    output_dict = sess.run(tensor_dict, feed_dict = {image_tensor: image})\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 929, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1152, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1328, in _do_run\n",
      "    run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1348, in _do_call\n",
      "    raise type(e)(node_def, op, message)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:3' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:3\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:3\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:3\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:3\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:3\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:3\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "Caused by op 'Preprocessor/map/TensorArray_2', defined at:\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 1431, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 346, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1080, in __init__\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-1d8adc307096>\", line 18, in <module>\n",
      "    tensors, graph = build_inference_graph(INFERENCE_GRAPH_PATH, d)\n",
      "  File \"<ipython-input-7-a0e1e0e6caa2>\", line 27, in build_inference_graph\n",
      "    name = ''\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 442, in import_graph_def\n",
      "    _ProcessNewOps(graph)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 234, in _ProcessNewOps\n",
      "    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in _add_new_tf_operations\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in <listcomp>\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3299, in _create_op_from_tf_operation\n",
      "    ret = Operation(c_op, self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n",
      "InvalidArgumentError (see above for traceback): Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:3' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:3\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:3\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:3\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:3\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:3\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:3\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "\n",
      "Exception in thread Thread-46:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1334, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1317, in _run_fn\n",
      "    self._extend_graph()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1352, in _extend_graph\n",
      "    tf_session.ExtendSession(self._session)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:2' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:2\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:2\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:2\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:2\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:2\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[{{node Preprocessor/map/TensorArray_2}} = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:2\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-9-04675268f0aa>\", line 5, in threaded_inference\n",
      "    output_dict = sess.run(tensor_dict, feed_dict = {image_tensor: image})\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 929, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1152, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1328, in _do_run\n",
      "    run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1348, in _do_call\n",
      "    raise type(e)(node_def, op, message)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:2' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:2\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:2\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:2\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:2\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:2\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:2\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "Caused by op 'Preprocessor/map/TensorArray_2', defined at:\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 1431, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 346, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1080, in __init__\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-1d8adc307096>\", line 18, in <module>\n",
      "    tensors, graph = build_inference_graph(INFERENCE_GRAPH_PATH, d)\n",
      "  File \"<ipython-input-7-a0e1e0e6caa2>\", line 27, in build_inference_graph\n",
      "    name = ''\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 442, in import_graph_def\n",
      "    _ProcessNewOps(graph)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 234, in _ProcessNewOps\n",
      "    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in _add_new_tf_operations\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in <listcomp>\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3299, in _create_op_from_tf_operation\n",
      "    ret = Operation(c_op, self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n",
      "InvalidArgumentError (see above for traceback): Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:2' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:2\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:2\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:2\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:2\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:2\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:2\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"image_tensor:0\", shape=(?, ?, ?, 3), dtype=uint8, device=/device:GPU:5)\n",
      "['/device:GPU:0', '/device:GPU:1', '/device:GPU:2', '/device:GPU:3', '/device:GPU:4', '/device:GPU:5', '/device:GPU:6', '/device:GPU:7']\n",
      "Tensor(\"image_tensor:0\", shape=(?, ?, ?, 3), dtype=uint8, device=/device:GPU:6)\n",
      "['/device:GPU:0', '/device:GPU:1', '/device:GPU:2', '/device:GPU:3', '/device:GPU:4', '/device:GPU:5', '/device:GPU:6', '/device:GPU:7']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-49:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1334, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1317, in _run_fn\n",
      "    self._extend_graph()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1352, in _extend_graph\n",
      "    tf_session.ExtendSession(self._session)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:5' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:5\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:5\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:5\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:5\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:5\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[{{node Preprocessor/map/TensorArray_2}} = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:5\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-9-04675268f0aa>\", line 5, in threaded_inference\n",
      "    output_dict = sess.run(tensor_dict, feed_dict = {image_tensor: image})\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 929, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1152, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1328, in _do_run\n",
      "    run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1348, in _do_call\n",
      "    raise type(e)(node_def, op, message)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:5' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:5\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:5\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:5\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:5\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:5\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:5\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "Caused by op 'Preprocessor/map/TensorArray_2', defined at:\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 1431, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 346, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1080, in __init__\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-1d8adc307096>\", line 18, in <module>\n",
      "    tensors, graph = build_inference_graph(INFERENCE_GRAPH_PATH, d)\n",
      "  File \"<ipython-input-7-a0e1e0e6caa2>\", line 27, in build_inference_graph\n",
      "    name = ''\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 442, in import_graph_def\n",
      "    _ProcessNewOps(graph)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 234, in _ProcessNewOps\n",
      "    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in _add_new_tf_operations\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in <listcomp>\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3299, in _create_op_from_tf_operation\n",
      "    ret = Operation(c_op, self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n",
      "InvalidArgumentError (see above for traceback): Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:5' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:5\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:5\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:5\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:5\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:5\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:5\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "\n",
      "Exception in thread Thread-48:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1334, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1317, in _run_fn\n",
      "    self._extend_graph()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1352, in _extend_graph\n",
      "    tf_session.ExtendSession(self._session)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:4' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:4\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:4\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:4\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:4\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:4\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[{{node Preprocessor/map/TensorArray_2}} = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:4\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-9-04675268f0aa>\", line 5, in threaded_inference\n",
      "    output_dict = sess.run(tensor_dict, feed_dict = {image_tensor: image})\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 929, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1152, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1328, in _do_run\n",
      "    run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1348, in _do_call\n",
      "    raise type(e)(node_def, op, message)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:4' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:4\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:4\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:4\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:4\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:4\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:4\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "Caused by op 'Preprocessor/map/TensorArray_2', defined at:\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 1431, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 346, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1080, in __init__\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-1d8adc307096>\", line 18, in <module>\n",
      "    tensors, graph = build_inference_graph(INFERENCE_GRAPH_PATH, d)\n",
      "  File \"<ipython-input-7-a0e1e0e6caa2>\", line 27, in build_inference_graph\n",
      "    name = ''\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 442, in import_graph_def\n",
      "    _ProcessNewOps(graph)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 234, in _ProcessNewOps\n",
      "    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in _add_new_tf_operations\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in <listcomp>\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3299, in _create_op_from_tf_operation\n",
      "    ret = Operation(c_op, self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n",
      "InvalidArgumentError (see above for traceback): Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:4' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:4\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:4\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:4\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:4\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:4\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:4\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "\n",
      "Exception in thread Thread-50:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1334, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1317, in _run_fn\n",
      "    self._extend_graph()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1352, in _extend_graph\n",
      "    tf_session.ExtendSession(self._session)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:6' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:6\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:6\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:6\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:6\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:6\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[{{node Preprocessor/map/TensorArray_2}} = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:6\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-9-04675268f0aa>\", line 5, in threaded_inference\n",
      "    output_dict = sess.run(tensor_dict, feed_dict = {image_tensor: image})\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 929, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1152, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1328, in _do_run\n",
      "    run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1348, in _do_call\n",
      "    raise type(e)(node_def, op, message)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:6' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:6\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:6\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:6\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:6\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:6\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:6\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "Caused by op 'Preprocessor/map/TensorArray_2', defined at:\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 1431, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 346, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1080, in __init__\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-1d8adc307096>\", line 18, in <module>\n",
      "    tensors, graph = build_inference_graph(INFERENCE_GRAPH_PATH, d)\n",
      "  File \"<ipython-input-7-a0e1e0e6caa2>\", line 27, in build_inference_graph\n",
      "    name = ''\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 442, in import_graph_def\n",
      "    _ProcessNewOps(graph)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 234, in _ProcessNewOps\n",
      "    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in _add_new_tf_operations\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in <listcomp>\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3299, in _create_op_from_tf_operation\n",
      "    ret = Operation(c_op, self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n",
      "InvalidArgumentError (see above for traceback): Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:6' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:6\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:6\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:6\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:6\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:6\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:6\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"image_tensor:0\", shape=(?, ?, ?, 3), dtype=uint8, device=/device:GPU:7)\n",
      "['/device:GPU:0', '/device:GPU:1', '/device:GPU:2', '/device:GPU:3', '/device:GPU:4', '/device:GPU:5', '/device:GPU:6', '/device:GPU:7']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-51:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1334, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1317, in _run_fn\n",
      "    self._extend_graph()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1352, in _extend_graph\n",
      "    tf_session.ExtendSession(self._session)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:7' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:7\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:7\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:7\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:7\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:7\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[{{node Preprocessor/map/TensorArray_2}} = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:7\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-9-04675268f0aa>\", line 5, in threaded_inference\n",
      "    output_dict = sess.run(tensor_dict, feed_dict = {image_tensor: image})\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 929, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1152, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1328, in _do_run\n",
      "    run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1348, in _do_call\n",
      "    raise type(e)(node_def, op, message)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:7' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:7\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:7\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:7\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:7\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:7\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:7\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "Caused by op 'Preprocessor/map/TensorArray_2', defined at:\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 1431, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 346, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1080, in __init__\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-1d8adc307096>\", line 18, in <module>\n",
      "    tensors, graph = build_inference_graph(INFERENCE_GRAPH_PATH, d)\n",
      "  File \"<ipython-input-7-a0e1e0e6caa2>\", line 27, in build_inference_graph\n",
      "    name = ''\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 442, in import_graph_def\n",
      "    _ProcessNewOps(graph)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 234, in _ProcessNewOps\n",
      "    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in _add_new_tf_operations\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in <listcomp>\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3299, in _create_op_from_tf_operation\n",
      "    ret = Operation(c_op, self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n",
      "InvalidArgumentError (see above for traceback): Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:7' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:7\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:7\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:7\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:7\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:7\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:7\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 49\n",
      "Tensor(\"image_tensor:0\", shape=(?, ?, ?, 3), dtype=uint8, device=/device:GPU:0)\n",
      "['/device:GPU:0', '/device:GPU:1', '/device:GPU:2', '/device:GPU:3', '/device:GPU:4', '/device:GPU:5', '/device:GPU:6', '/device:GPU:7']\n",
      "Tensor(\"image_tensor:0\", shape=(?, ?, ?, 3), dtype=uint8, device=/device:GPU:1)\n",
      "['/device:GPU:0', '/device:GPU:1', '/device:GPU:2', '/device:GPU:3', '/device:GPU:4', '/device:GPU:5', '/device:GPU:6', '/device:GPU:7']\n",
      "Tensor(\"image_tensor:0\", shape=(?, ?, ?, 3), dtype=uint8, device=/device:GPU:2)\n",
      "['/device:GPU:0', '/device:GPU:1', '/device:GPU:2', '/device:GPU:3', '/device:GPU:4', '/device:GPU:5', '/device:GPU:6', '/device:GPU:7']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-52:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1334, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1317, in _run_fn\n",
      "    self._extend_graph()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1352, in _extend_graph\n",
      "    tf_session.ExtendSession(self._session)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:0\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:0\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:0\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:0\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:0\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[{{node Preprocessor/map/TensorArray_2}} = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:0\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-9-04675268f0aa>\", line 5, in threaded_inference\n",
      "    output_dict = sess.run(tensor_dict, feed_dict = {image_tensor: image})\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 929, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1152, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1328, in _do_run\n",
      "    run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1348, in _do_call\n",
      "    raise type(e)(node_def, op, message)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:0\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:0\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:0\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:0\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:0\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:0\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "Caused by op 'Preprocessor/map/TensorArray_2', defined at:\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 1431, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 346, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1080, in __init__\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-1d8adc307096>\", line 18, in <module>\n",
      "    tensors, graph = build_inference_graph(INFERENCE_GRAPH_PATH, d)\n",
      "  File \"<ipython-input-7-a0e1e0e6caa2>\", line 27, in build_inference_graph\n",
      "    name = ''\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 442, in import_graph_def\n",
      "    _ProcessNewOps(graph)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 234, in _ProcessNewOps\n",
      "    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in _add_new_tf_operations\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in <listcomp>\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3299, in _create_op_from_tf_operation\n",
      "    ret = Operation(c_op, self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n",
      "InvalidArgumentError (see above for traceback): Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:0\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:0\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:0\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:0\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:0\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:0\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "\n",
      "Exception in thread Thread-53:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1334, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1317, in _run_fn\n",
      "    self._extend_graph()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1352, in _extend_graph\n",
      "    tf_session.ExtendSession(self._session)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:1' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:1\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:1\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:1\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:1\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:1\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[{{node Preprocessor/map/TensorArray_2}} = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:1\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-9-04675268f0aa>\", line 5, in threaded_inference\n",
      "    output_dict = sess.run(tensor_dict, feed_dict = {image_tensor: image})\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 929, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1152, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1328, in _do_run\n",
      "    run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1348, in _do_call\n",
      "    raise type(e)(node_def, op, message)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:1' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:1\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:1\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:1\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:1\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:1\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:1\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "Caused by op 'Preprocessor/map/TensorArray_2', defined at:\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 1431, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 346, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1080, in __init__\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-1d8adc307096>\", line 18, in <module>\n",
      "    tensors, graph = build_inference_graph(INFERENCE_GRAPH_PATH, d)\n",
      "  File \"<ipython-input-7-a0e1e0e6caa2>\", line 27, in build_inference_graph\n",
      "    name = ''\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 442, in import_graph_def\n",
      "    _ProcessNewOps(graph)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 234, in _ProcessNewOps\n",
      "    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in _add_new_tf_operations\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in <listcomp>\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3299, in _create_op_from_tf_operation\n",
      "    ret = Operation(c_op, self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n",
      "InvalidArgumentError (see above for traceback): Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:1' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:1\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:1\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:1\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:1\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:1\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:1\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"image_tensor:0\", shape=(?, ?, ?, 3), dtype=uint8, device=/device:GPU:3)\n",
      "['/device:GPU:0', '/device:GPU:1', '/device:GPU:2', '/device:GPU:3', '/device:GPU:4', '/device:GPU:5', '/device:GPU:6', '/device:GPU:7']\n",
      "Tensor(\"image_tensor:0\", shape=(?, ?, ?, 3), dtype=uint8, device=/device:GPU:4)\n",
      "['/device:GPU:0', '/device:GPU:1', '/device:GPU:2', '/device:GPU:3', '/device:GPU:4', '/device:GPU:5', '/device:GPU:6', '/device:GPU:7']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-54:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1334, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1317, in _run_fn\n",
      "    self._extend_graph()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1352, in _extend_graph\n",
      "    tf_session.ExtendSession(self._session)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:2' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:2\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:2\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:2\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:2\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:2\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[{{node Preprocessor/map/TensorArray_2}} = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:2\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-9-04675268f0aa>\", line 5, in threaded_inference\n",
      "    output_dict = sess.run(tensor_dict, feed_dict = {image_tensor: image})\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 929, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1152, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1328, in _do_run\n",
      "    run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1348, in _do_call\n",
      "    raise type(e)(node_def, op, message)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:2' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:2\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:2\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:2\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:2\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:2\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:2\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "Caused by op 'Preprocessor/map/TensorArray_2', defined at:\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 1431, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 346, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1080, in __init__\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-1d8adc307096>\", line 18, in <module>\n",
      "    tensors, graph = build_inference_graph(INFERENCE_GRAPH_PATH, d)\n",
      "  File \"<ipython-input-7-a0e1e0e6caa2>\", line 27, in build_inference_graph\n",
      "    name = ''\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 442, in import_graph_def\n",
      "    _ProcessNewOps(graph)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 234, in _ProcessNewOps\n",
      "    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in _add_new_tf_operations\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in <listcomp>\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3299, in _create_op_from_tf_operation\n",
      "    ret = Operation(c_op, self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n",
      "InvalidArgumentError (see above for traceback): Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:2' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:2\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:2\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:2\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:2\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:2\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:2\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "\n",
      "Exception in thread Thread-55:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1334, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1317, in _run_fn\n",
      "    self._extend_graph()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1352, in _extend_graph\n",
      "    tf_session.ExtendSession(self._session)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:3' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:3\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:3\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:3\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:3\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:3\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[{{node Preprocessor/map/TensorArray_2}} = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:3\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-9-04675268f0aa>\", line 5, in threaded_inference\n",
      "    output_dict = sess.run(tensor_dict, feed_dict = {image_tensor: image})\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 929, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1152, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1328, in _do_run\n",
      "    run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1348, in _do_call\n",
      "    raise type(e)(node_def, op, message)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:3' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:3\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:3\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:3\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:3\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:3\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:3\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "Caused by op 'Preprocessor/map/TensorArray_2', defined at:\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 1431, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 346, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1080, in __init__\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-1d8adc307096>\", line 18, in <module>\n",
      "    tensors, graph = build_inference_graph(INFERENCE_GRAPH_PATH, d)\n",
      "  File \"<ipython-input-7-a0e1e0e6caa2>\", line 27, in build_inference_graph\n",
      "    name = ''\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 442, in import_graph_def\n",
      "    _ProcessNewOps(graph)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 234, in _ProcessNewOps\n",
      "    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in _add_new_tf_operations\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in <listcomp>\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3299, in _create_op_from_tf_operation\n",
      "    ret = Operation(c_op, self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n",
      "InvalidArgumentError (see above for traceback): Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:3' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:3\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:3\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:3\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:3\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:3\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:3\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"image_tensor:0\", shape=(?, ?, ?, 3), dtype=uint8, device=/device:GPU:5)\n",
      "['/device:GPU:0', '/device:GPU:1', '/device:GPU:2', '/device:GPU:3', '/device:GPU:4', '/device:GPU:5', '/device:GPU:6', '/device:GPU:7']\n",
      "Tensor(\"image_tensor:0\", shape=(?, ?, ?, 3), dtype=uint8, device=/device:GPU:6)\n",
      "['/device:GPU:0', '/device:GPU:1', '/device:GPU:2', '/device:GPU:3', '/device:GPU:4', '/device:GPU:5', '/device:GPU:6', '/device:GPU:7']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-56:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1334, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1317, in _run_fn\n",
      "    self._extend_graph()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1352, in _extend_graph\n",
      "    tf_session.ExtendSession(self._session)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:4' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:4\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:4\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:4\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:4\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:4\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[{{node Preprocessor/map/TensorArray_2}} = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:4\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-9-04675268f0aa>\", line 5, in threaded_inference\n",
      "    output_dict = sess.run(tensor_dict, feed_dict = {image_tensor: image})\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 929, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1152, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1328, in _do_run\n",
      "    run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1348, in _do_call\n",
      "    raise type(e)(node_def, op, message)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:4' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:4\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:4\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:4\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:4\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:4\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:4\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "Caused by op 'Preprocessor/map/TensorArray_2', defined at:\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 1431, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 346, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1080, in __init__\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-1d8adc307096>\", line 18, in <module>\n",
      "    tensors, graph = build_inference_graph(INFERENCE_GRAPH_PATH, d)\n",
      "  File \"<ipython-input-7-a0e1e0e6caa2>\", line 27, in build_inference_graph\n",
      "    name = ''\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 442, in import_graph_def\n",
      "    _ProcessNewOps(graph)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 234, in _ProcessNewOps\n",
      "    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in _add_new_tf_operations\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in <listcomp>\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3299, in _create_op_from_tf_operation\n",
      "    ret = Operation(c_op, self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n",
      "InvalidArgumentError (see above for traceback): Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:4' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:4\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:4\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:4\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:4\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:4\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:4\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "\n",
      "Exception in thread Thread-57:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1334, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1317, in _run_fn\n",
      "    self._extend_graph()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1352, in _extend_graph\n",
      "    tf_session.ExtendSession(self._session)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:5' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:5\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:5\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:5\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:5\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:5\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[{{node Preprocessor/map/TensorArray_2}} = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:5\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-9-04675268f0aa>\", line 5, in threaded_inference\n",
      "    output_dict = sess.run(tensor_dict, feed_dict = {image_tensor: image})\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 929, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1152, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1328, in _do_run\n",
      "    run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1348, in _do_call\n",
      "    raise type(e)(node_def, op, message)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:5' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:5\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:5\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:5\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:5\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:5\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:5\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "Caused by op 'Preprocessor/map/TensorArray_2', defined at:\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 1431, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 346, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1080, in __init__\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-1d8adc307096>\", line 18, in <module>\n",
      "    tensors, graph = build_inference_graph(INFERENCE_GRAPH_PATH, d)\n",
      "  File \"<ipython-input-7-a0e1e0e6caa2>\", line 27, in build_inference_graph\n",
      "    name = ''\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 442, in import_graph_def\n",
      "    _ProcessNewOps(graph)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 234, in _ProcessNewOps\n",
      "    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in _add_new_tf_operations\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in <listcomp>\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3299, in _create_op_from_tf_operation\n",
      "    ret = Operation(c_op, self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n",
      "InvalidArgumentError (see above for traceback): Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:5' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:5\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:5\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:5\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:5\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:5\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:5\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"image_tensor:0\", shape=(?, ?, ?, 3), dtype=uint8, device=/device:GPU:7)\n",
      "['/device:GPU:0', '/device:GPU:1', '/device:GPU:2', '/device:GPU:3', '/device:GPU:4', '/device:GPU:5', '/device:GPU:6', '/device:GPU:7']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-58:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1334, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1317, in _run_fn\n",
      "    self._extend_graph()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1352, in _extend_graph\n",
      "    tf_session.ExtendSession(self._session)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:6' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:6\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:6\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:6\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:6\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:6\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[{{node Preprocessor/map/TensorArray_2}} = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:6\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-9-04675268f0aa>\", line 5, in threaded_inference\n",
      "    output_dict = sess.run(tensor_dict, feed_dict = {image_tensor: image})\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 929, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1152, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1328, in _do_run\n",
      "    run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1348, in _do_call\n",
      "    raise type(e)(node_def, op, message)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:6' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:6\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:6\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:6\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:6\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:6\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:6\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "Caused by op 'Preprocessor/map/TensorArray_2', defined at:\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 1431, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 346, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1080, in __init__\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-1d8adc307096>\", line 18, in <module>\n",
      "    tensors, graph = build_inference_graph(INFERENCE_GRAPH_PATH, d)\n",
      "  File \"<ipython-input-7-a0e1e0e6caa2>\", line 27, in build_inference_graph\n",
      "    name = ''\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 442, in import_graph_def\n",
      "    _ProcessNewOps(graph)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 234, in _ProcessNewOps\n",
      "    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in _add_new_tf_operations\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in <listcomp>\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3299, in _create_op_from_tf_operation\n",
      "    ret = Operation(c_op, self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n",
      "InvalidArgumentError (see above for traceback): Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:6' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:6\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:6\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:6\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:6\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:6\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:6\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "\n",
      "Exception in thread Thread-59:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1334, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1317, in _run_fn\n",
      "    self._extend_graph()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1352, in _extend_graph\n",
      "    tf_session.ExtendSession(self._session)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:7' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:7\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:7\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:7\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:7\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:7\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[{{node Preprocessor/map/TensorArray_2}} = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:7\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-9-04675268f0aa>\", line 5, in threaded_inference\n",
      "    output_dict = sess.run(tensor_dict, feed_dict = {image_tensor: image})\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 929, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1152, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1328, in _do_run\n",
      "    run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1348, in _do_call\n",
      "    raise type(e)(node_def, op, message)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:7' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:7\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:7\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:7\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:7\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:7\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:7\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "Caused by op 'Preprocessor/map/TensorArray_2', defined at:\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 1431, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 346, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1080, in __init__\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-1d8adc307096>\", line 18, in <module>\n",
      "    tensors, graph = build_inference_graph(INFERENCE_GRAPH_PATH, d)\n",
      "  File \"<ipython-input-7-a0e1e0e6caa2>\", line 27, in build_inference_graph\n",
      "    name = ''\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 442, in import_graph_def\n",
      "    _ProcessNewOps(graph)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 234, in _ProcessNewOps\n",
      "    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in _add_new_tf_operations\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in <listcomp>\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3299, in _create_op_from_tf_operation\n",
      "    ret = Operation(c_op, self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n",
      "InvalidArgumentError (see above for traceback): Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:7' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:7\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:7\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:7\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:7\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:7\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:7\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 57\n",
      "Tensor(\"image_tensor:0\", shape=(?, ?, ?, 3), dtype=uint8, device=/device:GPU:0)\n",
      "['/device:GPU:0', '/device:GPU:1', '/device:GPU:2', '/device:GPU:3', '/device:GPU:4', '/device:GPU:5', '/device:GPU:6', '/device:GPU:7']\n",
      "Tensor(\"image_tensor:0\", shape=(?, ?, ?, 3), dtype=uint8, device=/device:GPU:1)\n",
      "['/device:GPU:0', '/device:GPU:1', '/device:GPU:2', '/device:GPU:3', '/device:GPU:4', '/device:GPU:5', '/device:GPU:6', '/device:GPU:7']\n",
      "Tensor(\"image_tensor:0\", shape=(?, ?, ?, 3), dtype=uint8, device=/device:GPU:2)\n",
      "['/device:GPU:0', '/device:GPU:1', '/device:GPU:2', '/device:GPU:3', '/device:GPU:4', '/device:GPU:5', '/device:GPU:6', '/device:GPU:7']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-60:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1334, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1317, in _run_fn\n",
      "    self._extend_graph()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1352, in _extend_graph\n",
      "    tf_session.ExtendSession(self._session)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:0\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:0\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:0\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:0\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:0\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[{{node Preprocessor/map/TensorArray_2}} = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:0\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-9-04675268f0aa>\", line 5, in threaded_inference\n",
      "    output_dict = sess.run(tensor_dict, feed_dict = {image_tensor: image})\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 929, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1152, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1328, in _do_run\n",
      "    run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1348, in _do_call\n",
      "    raise type(e)(node_def, op, message)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:0\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:0\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:0\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:0\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:0\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:0\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "Caused by op 'Preprocessor/map/TensorArray_2', defined at:\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 1431, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 346, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1080, in __init__\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-1d8adc307096>\", line 18, in <module>\n",
      "    tensors, graph = build_inference_graph(INFERENCE_GRAPH_PATH, d)\n",
      "  File \"<ipython-input-7-a0e1e0e6caa2>\", line 27, in build_inference_graph\n",
      "    name = ''\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 442, in import_graph_def\n",
      "    _ProcessNewOps(graph)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 234, in _ProcessNewOps\n",
      "    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in _add_new_tf_operations\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in <listcomp>\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3299, in _create_op_from_tf_operation\n",
      "    ret = Operation(c_op, self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n",
      "InvalidArgumentError (see above for traceback): Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:0\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:0\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:0\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:0\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:0\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:0\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "\n",
      "Exception in thread Thread-61:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1334, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1317, in _run_fn\n",
      "    self._extend_graph()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1352, in _extend_graph\n",
      "    tf_session.ExtendSession(self._session)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:1' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:1\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:1\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:1\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:1\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:1\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[{{node Preprocessor/map/TensorArray_2}} = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:1\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-9-04675268f0aa>\", line 5, in threaded_inference\n",
      "    output_dict = sess.run(tensor_dict, feed_dict = {image_tensor: image})\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 929, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1152, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1328, in _do_run\n",
      "    run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1348, in _do_call\n",
      "    raise type(e)(node_def, op, message)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:1' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:1\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:1\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:1\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:1\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:1\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:1\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "Caused by op 'Preprocessor/map/TensorArray_2', defined at:\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 1431, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 346, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1080, in __init__\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-1d8adc307096>\", line 18, in <module>\n",
      "    tensors, graph = build_inference_graph(INFERENCE_GRAPH_PATH, d)\n",
      "  File \"<ipython-input-7-a0e1e0e6caa2>\", line 27, in build_inference_graph\n",
      "    name = ''\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 442, in import_graph_def\n",
      "    _ProcessNewOps(graph)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 234, in _ProcessNewOps\n",
      "    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in _add_new_tf_operations\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in <listcomp>\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3299, in _create_op_from_tf_operation\n",
      "    ret = Operation(c_op, self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n",
      "InvalidArgumentError (see above for traceback): Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:1' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:1\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:1\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:1\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:1\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:1\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:1\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"image_tensor:0\", shape=(?, ?, ?, 3), dtype=uint8, device=/device:GPU:3)\n",
      "['/device:GPU:0', '/device:GPU:1', '/device:GPU:2', '/device:GPU:3', '/device:GPU:4', '/device:GPU:5', '/device:GPU:6', '/device:GPU:7']\n",
      "Tensor(\"image_tensor:0\", shape=(?, ?, ?, 3), dtype=uint8, device=/device:GPU:4)\n",
      "['/device:GPU:0', '/device:GPU:1', '/device:GPU:2', '/device:GPU:3', '/device:GPU:4', '/device:GPU:5', '/device:GPU:6', '/device:GPU:7']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-63:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1334, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1317, in _run_fn\n",
      "    self._extend_graph()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1352, in _extend_graph\n",
      "    tf_session.ExtendSession(self._session)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:3' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:3\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:3\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:3\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:3\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:3\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[{{node Preprocessor/map/TensorArray_2}} = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:3\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-9-04675268f0aa>\", line 5, in threaded_inference\n",
      "    output_dict = sess.run(tensor_dict, feed_dict = {image_tensor: image})\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 929, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1152, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1328, in _do_run\n",
      "    run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1348, in _do_call\n",
      "    raise type(e)(node_def, op, message)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:3' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:3\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:3\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:3\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:3\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:3\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:3\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "Caused by op 'Preprocessor/map/TensorArray_2', defined at:\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 1431, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 346, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1080, in __init__\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-1d8adc307096>\", line 18, in <module>\n",
      "    tensors, graph = build_inference_graph(INFERENCE_GRAPH_PATH, d)\n",
      "  File \"<ipython-input-7-a0e1e0e6caa2>\", line 27, in build_inference_graph\n",
      "    name = ''\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 442, in import_graph_def\n",
      "    _ProcessNewOps(graph)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 234, in _ProcessNewOps\n",
      "    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in _add_new_tf_operations\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in <listcomp>\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3299, in _create_op_from_tf_operation\n",
      "    ret = Operation(c_op, self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n",
      "InvalidArgumentError (see above for traceback): Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:3' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:3\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:3\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:3\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:3\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:3\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:3\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "\n",
      "Exception in thread Thread-62:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1334, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1317, in _run_fn\n",
      "    self._extend_graph()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1352, in _extend_graph\n",
      "    tf_session.ExtendSession(self._session)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:2' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:2\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:2\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:2\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:2\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:2\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[{{node Preprocessor/map/TensorArray_2}} = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:2\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-9-04675268f0aa>\", line 5, in threaded_inference\n",
      "    output_dict = sess.run(tensor_dict, feed_dict = {image_tensor: image})\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 929, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1152, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1328, in _do_run\n",
      "    run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1348, in _do_call\n",
      "    raise type(e)(node_def, op, message)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:2' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:2\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:2\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:2\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:2\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:2\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:2\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "Caused by op 'Preprocessor/map/TensorArray_2', defined at:\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 1431, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 346, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1080, in __init__\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-1d8adc307096>\", line 18, in <module>\n",
      "    tensors, graph = build_inference_graph(INFERENCE_GRAPH_PATH, d)\n",
      "  File \"<ipython-input-7-a0e1e0e6caa2>\", line 27, in build_inference_graph\n",
      "    name = ''\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 442, in import_graph_def\n",
      "    _ProcessNewOps(graph)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 234, in _ProcessNewOps\n",
      "    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in _add_new_tf_operations\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in <listcomp>\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3299, in _create_op_from_tf_operation\n",
      "    ret = Operation(c_op, self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n",
      "InvalidArgumentError (see above for traceback): Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:2' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:2\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:2\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:2\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:2\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:2\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:2\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"image_tensor:0\", shape=(?, ?, ?, 3), dtype=uint8, device=/device:GPU:5)\n",
      "['/device:GPU:0', '/device:GPU:1', '/device:GPU:2', '/device:GPU:3', '/device:GPU:4', '/device:GPU:5', '/device:GPU:6', '/device:GPU:7']\n",
      "Tensor(\"image_tensor:0\", shape=(?, ?, ?, 3), dtype=uint8, device=/device:GPU:6)\n",
      "['/device:GPU:0', '/device:GPU:1', '/device:GPU:2', '/device:GPU:3', '/device:GPU:4', '/device:GPU:5', '/device:GPU:6', '/device:GPU:7']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-65:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1334, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1317, in _run_fn\n",
      "    self._extend_graph()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1352, in _extend_graph\n",
      "    tf_session.ExtendSession(self._session)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:5' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:5\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:5\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:5\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:5\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:5\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[{{node Preprocessor/map/TensorArray_2}} = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:5\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-9-04675268f0aa>\", line 5, in threaded_inference\n",
      "    output_dict = sess.run(tensor_dict, feed_dict = {image_tensor: image})\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 929, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1152, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1328, in _do_run\n",
      "    run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1348, in _do_call\n",
      "    raise type(e)(node_def, op, message)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:5' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:5\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:5\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:5\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:5\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:5\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:5\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "Caused by op 'Preprocessor/map/TensorArray_2', defined at:\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 1431, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 346, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1080, in __init__\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-1d8adc307096>\", line 18, in <module>\n",
      "    tensors, graph = build_inference_graph(INFERENCE_GRAPH_PATH, d)\n",
      "  File \"<ipython-input-7-a0e1e0e6caa2>\", line 27, in build_inference_graph\n",
      "    name = ''\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 442, in import_graph_def\n",
      "    _ProcessNewOps(graph)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 234, in _ProcessNewOps\n",
      "    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in _add_new_tf_operations\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in <listcomp>\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3299, in _create_op_from_tf_operation\n",
      "    ret = Operation(c_op, self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n",
      "InvalidArgumentError (see above for traceback): Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:5' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:5\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:5\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:5\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:5\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:5\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:5\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "\n",
      "Exception in thread Thread-64:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1334, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1317, in _run_fn\n",
      "    self._extend_graph()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1352, in _extend_graph\n",
      "    tf_session.ExtendSession(self._session)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:4' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:4\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:4\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:4\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:4\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:4\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[{{node Preprocessor/map/TensorArray_2}} = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:4\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-9-04675268f0aa>\", line 5, in threaded_inference\n",
      "    output_dict = sess.run(tensor_dict, feed_dict = {image_tensor: image})\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 929, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1152, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1328, in _do_run\n",
      "    run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1348, in _do_call\n",
      "    raise type(e)(node_def, op, message)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:4' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:4\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:4\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:4\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:4\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:4\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:4\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "Caused by op 'Preprocessor/map/TensorArray_2', defined at:\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 1431, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 346, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1080, in __init__\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-1d8adc307096>\", line 18, in <module>\n",
      "    tensors, graph = build_inference_graph(INFERENCE_GRAPH_PATH, d)\n",
      "  File \"<ipython-input-7-a0e1e0e6caa2>\", line 27, in build_inference_graph\n",
      "    name = ''\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 442, in import_graph_def\n",
      "    _ProcessNewOps(graph)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 234, in _ProcessNewOps\n",
      "    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in _add_new_tf_operations\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in <listcomp>\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3299, in _create_op_from_tf_operation\n",
      "    ret = Operation(c_op, self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n",
      "InvalidArgumentError (see above for traceback): Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:4' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:4\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:4\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:4\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:4\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:4\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:4\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "\n",
      "Exception in thread Thread-66:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1334, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1317, in _run_fn\n",
      "    self._extend_graph()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1352, in _extend_graph\n",
      "    tf_session.ExtendSession(self._session)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:6' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:6\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:6\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:6\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:6\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:6\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[{{node Preprocessor/map/TensorArray_2}} = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:6\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-9-04675268f0aa>\", line 5, in threaded_inference\n",
      "    output_dict = sess.run(tensor_dict, feed_dict = {image_tensor: image})\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 929, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1152, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1328, in _do_run\n",
      "    run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1348, in _do_call\n",
      "    raise type(e)(node_def, op, message)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:6' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:6\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:6\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:6\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:6\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:6\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:6\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "Caused by op 'Preprocessor/map/TensorArray_2', defined at:\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 1431, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 346, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1080, in __init__\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-1d8adc307096>\", line 18, in <module>\n",
      "    tensors, graph = build_inference_graph(INFERENCE_GRAPH_PATH, d)\n",
      "  File \"<ipython-input-7-a0e1e0e6caa2>\", line 27, in build_inference_graph\n",
      "    name = ''\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 442, in import_graph_def\n",
      "    _ProcessNewOps(graph)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 234, in _ProcessNewOps\n",
      "    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in _add_new_tf_operations\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in <listcomp>\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3299, in _create_op_from_tf_operation\n",
      "    ret = Operation(c_op, self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n",
      "InvalidArgumentError (see above for traceback): Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:6' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:6\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:6\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:6\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:6\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:6\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:6\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"image_tensor:0\", shape=(?, ?, ?, 3), dtype=uint8, device=/device:GPU:7)\n",
      "['/device:GPU:0', '/device:GPU:1', '/device:GPU:2', '/device:GPU:3', '/device:GPU:4', '/device:GPU:5', '/device:GPU:6', '/device:GPU:7']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-67:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1334, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1317, in _run_fn\n",
      "    self._extend_graph()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1352, in _extend_graph\n",
      "    tf_session.ExtendSession(self._session)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:7' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:7\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:7\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:7\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:7\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:7\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[{{node Preprocessor/map/TensorArray_2}} = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:7\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-9-04675268f0aa>\", line 5, in threaded_inference\n",
      "    output_dict = sess.run(tensor_dict, feed_dict = {image_tensor: image})\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 929, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1152, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1328, in _do_run\n",
      "    run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1348, in _do_call\n",
      "    raise type(e)(node_def, op, message)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:7' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:7\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:7\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:7\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:7\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:7\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:7\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "Caused by op 'Preprocessor/map/TensorArray_2', defined at:\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 1431, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 346, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1080, in __init__\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-1d8adc307096>\", line 18, in <module>\n",
      "    tensors, graph = build_inference_graph(INFERENCE_GRAPH_PATH, d)\n",
      "  File \"<ipython-input-7-a0e1e0e6caa2>\", line 27, in build_inference_graph\n",
      "    name = ''\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 442, in import_graph_def\n",
      "    _ProcessNewOps(graph)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 234, in _ProcessNewOps\n",
      "    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in _add_new_tf_operations\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in <listcomp>\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3299, in _create_op_from_tf_operation\n",
      "    ret = Operation(c_op, self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n",
      "InvalidArgumentError (see above for traceback): Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:7' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:7\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:7\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:7\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:7\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:7\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:7\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 65\n",
      "Tensor(\"image_tensor:0\", shape=(?, ?, ?, 3), dtype=uint8, device=/device:GPU:0)\n",
      "['/device:GPU:0', '/device:GPU:1', '/device:GPU:2', '/device:GPU:3', '/device:GPU:4', '/device:GPU:5', '/device:GPU:6', '/device:GPU:7']\n",
      "Tensor(\"image_tensor:0\", shape=(?, ?, ?, 3), dtype=uint8, device=/device:GPU:1)\n",
      "['/device:GPU:0', '/device:GPU:1', '/device:GPU:2', '/device:GPU:3', '/device:GPU:4', '/device:GPU:5', '/device:GPU:6', '/device:GPU:7']\n",
      "Tensor(\"image_tensor:0\", shape=(?, ?, ?, 3), dtype=uint8, device=/device:GPU:2)\n",
      "['/device:GPU:0', '/device:GPU:1', '/device:GPU:2', '/device:GPU:3', '/device:GPU:4', '/device:GPU:5', '/device:GPU:6', '/device:GPU:7']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-68:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1334, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1317, in _run_fn\n",
      "    self._extend_graph()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1352, in _extend_graph\n",
      "    tf_session.ExtendSession(self._session)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:0\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:0\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:0\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:0\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:0\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[{{node Preprocessor/map/TensorArray_2}} = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:0\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-9-04675268f0aa>\", line 5, in threaded_inference\n",
      "    output_dict = sess.run(tensor_dict, feed_dict = {image_tensor: image})\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 929, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1152, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1328, in _do_run\n",
      "    run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1348, in _do_call\n",
      "    raise type(e)(node_def, op, message)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:0\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:0\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:0\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:0\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:0\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:0\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "Caused by op 'Preprocessor/map/TensorArray_2', defined at:\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 1431, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 346, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1080, in __init__\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-1d8adc307096>\", line 18, in <module>\n",
      "    tensors, graph = build_inference_graph(INFERENCE_GRAPH_PATH, d)\n",
      "  File \"<ipython-input-7-a0e1e0e6caa2>\", line 27, in build_inference_graph\n",
      "    name = ''\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 442, in import_graph_def\n",
      "    _ProcessNewOps(graph)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 234, in _ProcessNewOps\n",
      "    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in _add_new_tf_operations\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in <listcomp>\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3299, in _create_op_from_tf_operation\n",
      "    ret = Operation(c_op, self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n",
      "InvalidArgumentError (see above for traceback): Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:0\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:0\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:0\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:0\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:0\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:0\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"image_tensor:0\", shape=(?, ?, ?, 3), dtype=uint8, device=/device:GPU:3)\n",
      "['/device:GPU:0', '/device:GPU:1', '/device:GPU:2', '/device:GPU:3', '/device:GPU:4', '/device:GPU:5', '/device:GPU:6', '/device:GPU:7']\n",
      "Tensor(\"image_tensor:0\", shape=(?, ?, ?, 3), dtype=uint8, device=/device:GPU:4)\n",
      "['/device:GPU:0', '/device:GPU:1', '/device:GPU:2', '/device:GPU:3', '/device:GPU:4', '/device:GPU:5', '/device:GPU:6', '/device:GPU:7']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-70:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1334, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1317, in _run_fn\n",
      "    self._extend_graph()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1352, in _extend_graph\n",
      "    tf_session.ExtendSession(self._session)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:2' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:2\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:2\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:2\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:2\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:2\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[{{node Preprocessor/map/TensorArray_2}} = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:2\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-9-04675268f0aa>\", line 5, in threaded_inference\n",
      "    output_dict = sess.run(tensor_dict, feed_dict = {image_tensor: image})\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 929, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1152, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1328, in _do_run\n",
      "    run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1348, in _do_call\n",
      "    raise type(e)(node_def, op, message)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:2' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:2\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:2\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:2\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:2\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:2\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:2\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "Caused by op 'Preprocessor/map/TensorArray_2', defined at:\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 1431, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 346, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1080, in __init__\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-1d8adc307096>\", line 18, in <module>\n",
      "    tensors, graph = build_inference_graph(INFERENCE_GRAPH_PATH, d)\n",
      "  File \"<ipython-input-7-a0e1e0e6caa2>\", line 27, in build_inference_graph\n",
      "    name = ''\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 442, in import_graph_def\n",
      "    _ProcessNewOps(graph)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 234, in _ProcessNewOps\n",
      "    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in _add_new_tf_operations\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in <listcomp>\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3299, in _create_op_from_tf_operation\n",
      "    ret = Operation(c_op, self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n",
      "InvalidArgumentError (see above for traceback): Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:2' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:2\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:2\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:2\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:2\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:2\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:2\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "\n",
      "Exception in thread Thread-69:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1334, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1317, in _run_fn\n",
      "    self._extend_graph()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1352, in _extend_graph\n",
      "    tf_session.ExtendSession(self._session)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:1' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:1\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:1\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:1\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:1\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:1\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[{{node Preprocessor/map/TensorArray_2}} = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:1\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-9-04675268f0aa>\", line 5, in threaded_inference\n",
      "    output_dict = sess.run(tensor_dict, feed_dict = {image_tensor: image})\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 929, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1152, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1328, in _do_run\n",
      "    run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1348, in _do_call\n",
      "    raise type(e)(node_def, op, message)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:1' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:1\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:1\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:1\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:1\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:1\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:1\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "Caused by op 'Preprocessor/map/TensorArray_2', defined at:\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 1431, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 346, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1080, in __init__\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-1d8adc307096>\", line 18, in <module>\n",
      "    tensors, graph = build_inference_graph(INFERENCE_GRAPH_PATH, d)\n",
      "  File \"<ipython-input-7-a0e1e0e6caa2>\", line 27, in build_inference_graph\n",
      "    name = ''\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 442, in import_graph_def\n",
      "    _ProcessNewOps(graph)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 234, in _ProcessNewOps\n",
      "    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in _add_new_tf_operations\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in <listcomp>\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3299, in _create_op_from_tf_operation\n",
      "    ret = Operation(c_op, self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n",
      "InvalidArgumentError (see above for traceback): Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:1' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:1\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:1\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:1\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:1\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:1\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:1\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-72:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1334, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1317, in _run_fn\n",
      "    self._extend_graph()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1352, in _extend_graph\n",
      "    tf_session.ExtendSession(self._session)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:4' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:4\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:4\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:4\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:4\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:4\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[{{node Preprocessor/map/TensorArray_2}} = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:4\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-9-04675268f0aa>\", line 5, in threaded_inference\n",
      "    output_dict = sess.run(tensor_dict, feed_dict = {image_tensor: image})\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 929, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1152, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1328, in _do_run\n",
      "    run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1348, in _do_call\n",
      "    raise type(e)(node_def, op, message)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:4' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:4\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:4\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:4\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:4\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:4\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:4\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "Caused by op 'Preprocessor/map/TensorArray_2', defined at:\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 1431, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 346, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1080, in __init__\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-1d8adc307096>\", line 18, in <module>\n",
      "    tensors, graph = build_inference_graph(INFERENCE_GRAPH_PATH, d)\n",
      "  File \"<ipython-input-7-a0e1e0e6caa2>\", line 27, in build_inference_graph\n",
      "    name = ''\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 442, in import_graph_def\n",
      "    _ProcessNewOps(graph)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 234, in _ProcessNewOps\n",
      "    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in _add_new_tf_operations\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in <listcomp>\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3299, in _create_op_from_tf_operation\n",
      "    ret = Operation(c_op, self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n",
      "InvalidArgumentError (see above for traceback): Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:4' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:4\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:4\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:4\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:4\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:4\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:4\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "\n",
      "Exception in thread Thread-71:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1334, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1317, in _run_fn\n",
      "    self._extend_graph()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1352, in _extend_graph\n",
      "    tf_session.ExtendSession(self._session)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:3' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:3\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:3\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:3\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:3\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:3\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[{{node Preprocessor/map/TensorArray_2}} = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:3\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-9-04675268f0aa>\", line 5, in threaded_inference\n",
      "    output_dict = sess.run(tensor_dict, feed_dict = {image_tensor: image})\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 929, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1152, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1328, in _do_run\n",
      "    run_metadata)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1348, in _do_call\n",
      "    raise type(e)(node_def, op, message)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:3' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:3\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:3\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:3\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:3\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:3\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:3\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "Caused by op 'Preprocessor/map/TensorArray_2', defined at:\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 1431, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 346, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1080, in __init__\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-1d8adc307096>\", line 18, in <module>\n",
      "    tensors, graph = build_inference_graph(INFERENCE_GRAPH_PATH, d)\n",
      "  File \"<ipython-input-7-a0e1e0e6caa2>\", line 27, in build_inference_graph\n",
      "    name = ''\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 442, in import_graph_def\n",
      "    _ProcessNewOps(graph)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 234, in _ProcessNewOps\n",
      "    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in _add_new_tf_operations\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3440, in <listcomp>\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3299, in _create_op_from_tf_operation\n",
      "    ret = Operation(c_op, self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n",
      "InvalidArgumentError (see above for traceback): Cannot assign a device for operation Preprocessor/map/TensorArray_2: Could not satisfy explicit device specification '/device:GPU:3' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and devices: \n",
      "TensorArrayGatherV3: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayWriteV3: CPU XLA_CPU XLA_GPU \n",
      "TensorArraySizeV3: GPU CPU XLA_CPU XLA_GPU \n",
      "Enter: GPU CPU XLA_CPU XLA_GPU \n",
      "TensorArrayV3: CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members and user-requested devices:\n",
      "  Preprocessor/map/TensorArray_2 (TensorArrayV3) /device:GPU:3\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3/Enter (Enter) /device:GPU:3\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArraySizeV3 (TensorArraySizeV3) /device:GPU:3\n",
      "  Preprocessor/map/while/TensorArrayWrite_1/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:3\n",
      "  Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3 (TensorArrayGatherV3) /device:GPU:3\n",
      "\n",
      "Registered kernels:\n",
      "  device='XLA_CPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, ..., DT_QINT32, DT_BFLOAT16, DT_HALF, DT_UINT32, DT_UINT64]\n",
      "  device='CPU'\n",
      "  device='GPU'; dtype in [DT_BFLOAT16]\n",
      "  device='GPU'; dtype in [DT_INT64]\n",
      "  device='GPU'; dtype in [DT_COMPLEX128]\n",
      "  device='GPU'; dtype in [DT_COMPLEX64]\n",
      "  device='GPU'; dtype in [DT_DOUBLE]\n",
      "  device='GPU'; dtype in [DT_FLOAT]\n",
      "  device='GPU'; dtype in [DT_HALF]\n",
      "\n",
      "\t [[node Preprocessor/map/TensorArray_2 (defined at <ipython-input-7-a0e1e0e6caa2>:27)  = TensorArrayV3[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, element_shape=<unknown>, identical_element_shapes=true, tensor_array_name=\"\", _device=\"/device:GPU:3\"](Preprocessor/map/strided_slice)]]\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-1d8adc307096>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;31m#        sess.run(tf.global_variables_initializer())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;31m#        loc_image = sess.run(image_it)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0mloc_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m             thread = Thread(target = threaded_inference, \n\u001b[1;32m     40\u001b[0m                             args = (devices[idx], tf_dict[idx]['out'], tf_dict[idx]['in'], tg_dict[idx], loc_image, i))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "ds = create_dataset(IMAGE_PATH, IMAGE_DIMS)\n",
    "ds = ds.prefetch(BATCH_NUM*2).batch(BATCH_NUM)\n",
    "it = ds.make_one_shot_iterator()\n",
    "\n",
    "# This is needed to display the images.\n",
    "%matplotlib inline\n",
    "\n",
    "devices = get_available_gpus()\n",
    "\n",
    "tf.logging.info('Reading graph and building model specified for the different cluster devices')\n",
    "\n",
    "tf_dict = []\n",
    "tg_dict = []\n",
    "n = 0\n",
    "for d in devices:\n",
    "    print(d + \" loading graph done!\")\n",
    "    tensors, graph = build_inference_graph(INFERENCE_GRAPH_PATH, d)\n",
    "    tf_dict.append(tensors)\n",
    "    tg_dict.append(graph)\n",
    "\n",
    "#image_it = it.get_next()\n",
    "\n",
    "#threads = []\n",
    "\n",
    "i = 1\n",
    "j = 1\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        threads = []\n",
    "        print('Step: ' + str(i))\n",
    "        for idx in range(len(tf_dict)):\n",
    "            loc_image = []\n",
    "            #with tf.Session() as sess:\n",
    "            #        sess.run(tf.global_variables_initializer())\n",
    "            #        loc_image = sess.run(image_it)\n",
    "            loc_image = np.arange(200*300*300*3).reshape((200, 300, 300, 3))\n",
    "            thread = Thread(target = threaded_inference, \n",
    "                            args = (devices[idx], tf_dict[idx]['out'], tf_dict[idx]['in'], tg_dict[idx], loc_image, i))\n",
    "            i += 1\n",
    "            thread.start()\n",
    "            threads.append(thread)\n",
    "\n",
    "        for t in threads:\n",
    "            t.join()\n",
    "\n",
    "\n",
    "except tf.errors.OutOfRangeError:\n",
    "    tf.logging.info('Finished processing records')\n",
    "    for t in vis_threads:\n",
    "        t.join()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ds = create_dataset(IMAGE_PATH, IMAGE_DIMS)\n",
    "ds = ds.prefetch(BATCH_NUM*2).batch(BATCH_NUM)\n",
    "it = ds.make_one_shot_iterator()\n",
    "\n",
    "# This is needed to display the images.\n",
    "%matplotlib inline\n",
    "\n",
    "#config=tf.ConfigProto(log_device_placement=True)\n",
    "\n",
    "\n",
    "#tf.logging.info('Reading input from files and connecting to graph')\n",
    "#image_tensor = build_input(image_path)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    devices = get_available_gpus()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    tf.logging.info('Reading graph and building model specified for the different cluster devices')\n",
    "\n",
    "    tf_dict = []\n",
    "    tg_dict = []\n",
    "    for d in devices:\n",
    "        print(d + \" loading graph done!\")\n",
    "        tensors, graph = build_inference_graph(INFERENCE_GRAPH_PATH, d)\n",
    "        tf_dict.append(tensors)\n",
    "        tg_dict.append(graph)\n",
    "        \n",
    "    print(tg_dict)\n",
    "    image_it = it.get_next()\n",
    "\n",
    "    threads = []\n",
    "    \n",
    "\n",
    "    i = 1\n",
    "    j = 1\n",
    "    try:\n",
    "        while True:\n",
    "            print('Step: ' + str(i))\n",
    "            start = time.time()\n",
    "\n",
    "            output_multi_device = []\n",
    "            input_feed_dict = {}\n",
    "            images = []\n",
    "            '''\n",
    "            for idx in tf_dict:\n",
    "\n",
    "                output_multi_device.append(idx['out'])\n",
    "                loc_image = sess.run(image_it)\n",
    "                print(idx['in'])\n",
    "                input_feed_dict[idx['in']] = loc_image\n",
    "                images.append(loc_image)\n",
    "\n",
    "            outputs = sess.run(output_multi_device, input_feed_dict)\n",
    "            #pprint.pprint(outputs)\n",
    "\n",
    "            if VISUALIZE:\n",
    "                for count in range(len(tf_dict)):\n",
    "                    thread = Thread(target = threaded_function, args = (images[count], outputs[count], i, count))\n",
    "                    thread.start()\n",
    "                    threads.append(thread)\n",
    "            i += 1\n",
    "            '''\n",
    "            threads = []\n",
    "            for idx in range(len(tf_dict)):\n",
    "                loc_image = []\n",
    "                #with tf.Session() as sess:\n",
    "                #        sess.run(tf.global_variables_initializer())\n",
    "                #        loc_image = sess.run(image_it)\n",
    "                loc_image = np.arange(200*300*300*3).reshape((200, 300, 300, 3))\n",
    "                thread = Thread(target = threaded_inference, \n",
    "                                args = (devices[idx], tf_dict[idx]['out'], tf_dict[idx]['in'], tg_dict[idx], loc_image, i))\n",
    "                i += 1\n",
    "                thread.start()\n",
    "                threads.append(thread)\n",
    "\n",
    "            for t in threads:\n",
    "                t.join()\n",
    "            \n",
    "    except tf.errors.OutOfRangeError:\n",
    "        tf.logging.info('Finished processing records')\n",
    "        for t in vis_threads:\n",
    "            t.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf_dict[2]['out']['num_detections'])\n",
    "print(tf_dict[2]['in'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tensor_dict)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "object_detection_tutorial.ipynb?workspaceId=ronnyvotel:python_inference::citc",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
